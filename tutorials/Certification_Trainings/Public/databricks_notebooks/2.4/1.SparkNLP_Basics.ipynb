{"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"colab_type":"text","id":"3inuQHTI-G-P"}},{"cell_type":"markdown","source":["# Spark NLP Basics"],"metadata":{"colab_type":"text","id":"rXqTJvvh-MCU"}},{"cell_type":"markdown","source":["## 1. Start Spark Session"],"metadata":{"colab_type":"text","id":"ODtmoBwfoX3T"}},{"cell_type":"code","source":["import sparknlp\n\nspark = sparknlp.start()\n\nprint(\"Spark NLP version\", sparknlp.version())\n\nprint(\"Apache Spark version:\", spark.version)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"colab_type":"code","id":"5q8yjPy8oUBj","outputId":"dd440a17-e2c6-41ac-9fed-802cab16c072"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Spark NLP version 2.5.2\nApache Spark version: 2.4.5\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["#!pip install spark-nlp==2.4.5\n\nimport sparknlp\n\nsparknlp.version()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[28]: &#39;2.5.2&#39;</div>"]}}],"execution_count":5},{"cell_type":"code","source":["!pip install spark-nlp==2.4.5"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["`sparknlp.start()` will start or get SparkSession with predefined parameters hardcoded in `spark-nlp/python/sparknlp/__init__.py`. here is what is going on on the background when you run `sparknlp.start()`"],"metadata":{}},{"cell_type":"code","source":["# repo >> spark-nlp/python/sparknlp/__init__.py\n\nfrom pyspark.sql import SparkSession\n\ndef start(gpu=False):\n    builder = SparkSession.builder \\\n        .appName(\"Spark NLP\") \\\n        .master(\"local[*]\") \\\n        .config(\"spark.driver.memory\", \"16G\") \\\n        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n        .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\n    if gpu:\n        builder.config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp-gpu_2.11:2.4.5\")\n    else:\n        builder.config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5\")\n        \n    return builder.getOrCreate()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["If you want to start `SparkSession` with your own parameters or you need to load the required jars/packages from your local disk, or you have no internet connection (that would be needed to pull the required packages from internet), you can skip `sparknlp.start()` and start your session manually as shown below."],"metadata":{}},{"cell_type":"code","source":["\"\"\"\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n    .appName(\"Spark NLP Enterprise 2.4.5\") \\\n    .master(\"local[8]\") \\\n    .config(\"spark.driver.memory\",\"12G\") \\\n    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n    .config(\"spark.kryoserializer.buffer.max\", \"800M\")\\\n    .config(\"spark.jars\", \"{}spark-nlp-2.4.5.jar,{}spark-nlp-jsl-2.4.5.jar\".format(jar_path,jar_path)) \\\n    .getOrCreate()\n    \n\"\"\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[31]: &#39;\\nfrom pyspark.sql import SparkSession\\n\\nspark = SparkSession.builder     .appName(&#34;Spark NLP Enterprise 2.4.5&#34;)     .master(&#34;local[8]&#34;)     .config(&#34;spark.driver.memory&#34;,&#34;12G&#34;)     .config(&#34;spark.driver.maxResultSize&#34;, &#34;2G&#34;)     .config(&#34;spark.serializer&#34;, &#34;org.apache.spark.serializer.KryoSerializer&#34;)     .config(&#34;spark.kryoserializer.buffer.max&#34;, &#34;800M&#34;)    .config(&#34;spark.jars&#34;, &#34;{}spark-nlp-2.4.5.jar,{}spark-nlp-jsl-2.4.5.jar&#34;.format(jar_path,jar_path))     .getOrCreate()\\n    \\n&#39;</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["## 2. Using Pretrained Pipelines"],"metadata":{"colab_type":"text","id":"YPJy2G5Zp56w"}},{"cell_type":"markdown","source":["https://github.com/JohnSnowLabs/spark-nlp-models"],"metadata":{"colab_type":"text","id":"e1Gy-bYBrLyT"}},{"cell_type":"code","source":["from sparknlp.pretrained import PretrainedPipeline"],"metadata":{"colab":{},"colab_type":"code","id":"SgFMrbinpN5_"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["testDoc = '''\nPeter is a very good persn.\nMy life in Russia is very intersting.\nJohn and Peter are brothrs. However they don't support each other that much.\nLucas Nogal Dunbercker is no longer happy. He has a good car though.\nEurope is very culture rich. There are huge churches! and big houses!\n'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["### Explain Document ML"],"metadata":{"colab_type":"text","id":"Kn7jx6sJtCL1"}},{"cell_type":"markdown","source":["**Stages**\n- DocumentAssembler\n- SentenceDetector\n- Tokenizer\n- Lemmatizer\n- Stemmer\n- Part of Speech\n- SpellChecker (Norvig)"],"metadata":{"colab_type":"text","id":"HK5Tz3ChtJfq"}},{"cell_type":"code","source":["pipeline = PretrainedPipeline('explain_document_ml', lang='en')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"colab_type":"code","id":"2jbBIjhop_Yu","outputId":"0806dbd5-a5e8-4a9d-b9de-22a750e5a21e"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">explain_document_ml download started this may take some time.\nApprox size to download 9.4 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["##%%time\nresult = pipeline.annotate(testDoc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"colab_type":"code","id":"29rw6Cgjrvfg","outputId":"7bf8fded-431e-4859-a69d-749993e2c760"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["result.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"dwku5nc8r5G7","outputId":"71b14b5c-4659-484d-df9d-489ef15bb13d"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[36]: dict_keys([&#39;document&#39;, &#39;spell&#39;, &#39;pos&#39;, &#39;lemmas&#39;, &#39;token&#39;, &#39;stems&#39;, &#39;sentence&#39;])</div>"]}}],"execution_count":19},{"cell_type":"code","source":["result['sentence']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"colab_type":"code","id":"PufrzfGuvaBZ","outputId":"ef6ccc4b-d791-452b-f926-b2e0dbbbebbe"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[37]: [&#39;Peter is a very good persn.&#39;,\n &#39;My life in Russia is very intersting.&#39;,\n &#39;John and Peter are brothrs.&#39;,\n &#34;However they don&#39;t support each other that much.&#34;,\n &#39;Lucas Nogal Dunbercker is no longer happy.&#39;,\n &#39;He has a good car though.&#39;,\n &#39;Europe is very culture rich.&#39;,\n &#39;There are huge churches!&#39;,\n &#39;and big houses!&#39;]</div>"]}}],"execution_count":20},{"cell_type":"code","source":["result['token']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":710},"colab_type":"code","id":"eaalY5rcr8pV","outputId":"8c8c5def-18e9-4fe6-c3ea-e1ae1ea76132"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[38]: [&#39;Peter&#39;,\n &#39;is&#39;,\n &#39;a&#39;,\n &#39;very&#39;,\n &#39;good&#39;,\n &#39;persn&#39;,\n &#39;.&#39;,\n &#39;My&#39;,\n &#39;life&#39;,\n &#39;in&#39;,\n &#39;Russia&#39;,\n &#39;is&#39;,\n &#39;very&#39;,\n &#39;intersting&#39;,\n &#39;.&#39;,\n &#39;John&#39;,\n &#39;and&#39;,\n &#39;Peter&#39;,\n &#39;are&#39;,\n &#39;brothrs&#39;,\n &#39;.&#39;,\n &#39;However&#39;,\n &#39;they&#39;,\n &#34;don&#39;t&#34;,\n &#39;support&#39;,\n &#39;each&#39;,\n &#39;other&#39;,\n &#39;that&#39;,\n &#39;much&#39;,\n &#39;.&#39;,\n &#39;Lucas&#39;,\n &#39;Nogal&#39;,\n &#39;Dunbercker&#39;,\n &#39;is&#39;,\n &#39;no&#39;,\n &#39;longer&#39;,\n &#39;happy&#39;,\n &#39;.&#39;,\n &#39;He&#39;,\n &#39;has&#39;,\n &#39;a&#39;,\n &#39;good&#39;,\n &#39;car&#39;,\n &#39;though&#39;,\n &#39;.&#39;,\n &#39;Europe&#39;,\n &#39;is&#39;,\n &#39;very&#39;,\n &#39;culture&#39;,\n &#39;rich&#39;,\n &#39;.&#39;,\n &#39;There&#39;,\n &#39;are&#39;,\n &#39;huge&#39;,\n &#39;churches&#39;,\n &#39;!&#39;,\n &#39;and&#39;,\n &#39;big&#39;,\n &#39;houses&#39;,\n &#39;!&#39;]</div>"]}}],"execution_count":21},{"cell_type":"code","source":["list(zip(result['token'], result['pos']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":710},"colab_type":"code","id":"7rxuH6-ks41J","outputId":"3074412d-42f5-48b3-b709-2ab583157014"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[39]: [(&#39;Peter&#39;, &#39;NNP&#39;),\n (&#39;is&#39;, &#39;VBZ&#39;),\n (&#39;a&#39;, &#39;DT&#39;),\n (&#39;very&#39;, &#39;RB&#39;),\n (&#39;good&#39;, &#39;JJ&#39;),\n (&#39;persn&#39;, &#39;NN&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;My&#39;, &#39;PRP$&#39;),\n (&#39;life&#39;, &#39;NN&#39;),\n (&#39;in&#39;, &#39;IN&#39;),\n (&#39;Russia&#39;, &#39;NNP&#39;),\n (&#39;is&#39;, &#39;VBZ&#39;),\n (&#39;very&#39;, &#39;RB&#39;),\n (&#39;intersting&#39;, &#39;JJ&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;John&#39;, &#39;NNP&#39;),\n (&#39;and&#39;, &#39;CC&#39;),\n (&#39;Peter&#39;, &#39;NNP&#39;),\n (&#39;are&#39;, &#39;VBP&#39;),\n (&#39;brothrs&#39;, &#39;NNS&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;However&#39;, &#39;RB&#39;),\n (&#39;they&#39;, &#39;PRP&#39;),\n (&#34;don&#39;t&#34;, &#39;VBP&#39;),\n (&#39;support&#39;, &#39;VB&#39;),\n (&#39;each&#39;, &#39;DT&#39;),\n (&#39;other&#39;, &#39;JJ&#39;),\n (&#39;that&#39;, &#39;IN&#39;),\n (&#39;much&#39;, &#39;JJ&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;Lucas&#39;, &#39;NNP&#39;),\n (&#39;Nogal&#39;, &#39;NNP&#39;),\n (&#39;Dunbercker&#39;, &#39;NNP&#39;),\n (&#39;is&#39;, &#39;VBZ&#39;),\n (&#39;no&#39;, &#39;DT&#39;),\n (&#39;longer&#39;, &#39;RB&#39;),\n (&#39;happy&#39;, &#39;JJ&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;He&#39;, &#39;PRP&#39;),\n (&#39;has&#39;, &#39;VBZ&#39;),\n (&#39;a&#39;, &#39;DT&#39;),\n (&#39;good&#39;, &#39;JJ&#39;),\n (&#39;car&#39;, &#39;NN&#39;),\n (&#39;though&#39;, &#39;IN&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;Europe&#39;, &#39;NNP&#39;),\n (&#39;is&#39;, &#39;VBZ&#39;),\n (&#39;very&#39;, &#39;RB&#39;),\n (&#39;culture&#39;, &#39;RB&#39;),\n (&#39;rich&#39;, &#39;JJ&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;There&#39;, &#39;EX&#39;),\n (&#39;are&#39;, &#39;VBP&#39;),\n (&#39;huge&#39;, &#39;JJ&#39;),\n (&#39;churches&#39;, &#39;NNS&#39;),\n (&#39;!&#39;, &#39;.&#39;),\n (&#39;and&#39;, &#39;CC&#39;),\n (&#39;big&#39;, &#39;JJ&#39;),\n (&#39;houses&#39;, &#39;NNS&#39;),\n (&#39;!&#39;, &#39;.&#39;)]</div>"]}}],"execution_count":22},{"cell_type":"code","source":["list(zip(result['token'], result['lemmas'], result['stems'], result['spell']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":710},"colab_type":"code","id":"gteKLMhysCC8","outputId":"68e1e28a-b458-4443-b189-50fccd7b848e"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[40]: [(&#39;Peter&#39;, &#39;Peter&#39;, &#39;peter&#39;, &#39;Peter&#39;),\n (&#39;is&#39;, &#39;be&#39;, &#39;i&#39;, &#39;is&#39;),\n (&#39;a&#39;, &#39;a&#39;, &#39;a&#39;, &#39;a&#39;),\n (&#39;very&#39;, &#39;very&#39;, &#39;veri&#39;, &#39;very&#39;),\n (&#39;good&#39;, &#39;good&#39;, &#39;good&#39;, &#39;good&#39;),\n (&#39;persn&#39;, &#39;person&#39;, &#39;person&#39;, &#39;person&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;My&#39;, &#39;My&#39;, &#39;my&#39;, &#39;My&#39;),\n (&#39;life&#39;, &#39;life&#39;, &#39;life&#39;, &#39;life&#39;),\n (&#39;in&#39;, &#39;in&#39;, &#39;in&#39;, &#39;in&#39;),\n (&#39;Russia&#39;, &#39;Russia&#39;, &#39;russia&#39;, &#39;Russia&#39;),\n (&#39;is&#39;, &#39;be&#39;, &#39;i&#39;, &#39;is&#39;),\n (&#39;very&#39;, &#39;very&#39;, &#39;veri&#39;, &#39;very&#39;),\n (&#39;intersting&#39;, &#39;interest&#39;, &#39;interest&#39;, &#39;interesting&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;John&#39;, &#39;John&#39;, &#39;john&#39;, &#39;John&#39;),\n (&#39;and&#39;, &#39;and&#39;, &#39;and&#39;, &#39;and&#39;),\n (&#39;Peter&#39;, &#39;Peter&#39;, &#39;peter&#39;, &#39;Peter&#39;),\n (&#39;are&#39;, &#39;be&#39;, &#39;ar&#39;, &#39;are&#39;),\n (&#39;brothrs&#39;, &#39;broth&#39;, &#39;broth&#39;, &#39;broths&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;However&#39;, &#39;However&#39;, &#39;howev&#39;, &#39;However&#39;),\n (&#39;they&#39;, &#39;they&#39;, &#39;thei&#39;, &#39;they&#39;),\n (&#34;don&#39;t&#34;, &#34;don&#39;t&#34;, &#34;don&#39;t&#34;, &#34;don&#39;t&#34;),\n (&#39;support&#39;, &#39;support&#39;, &#39;support&#39;, &#39;support&#39;),\n (&#39;each&#39;, &#39;each&#39;, &#39;each&#39;, &#39;each&#39;),\n (&#39;other&#39;, &#39;other&#39;, &#39;other&#39;, &#39;other&#39;),\n (&#39;that&#39;, &#39;that&#39;, &#39;that&#39;, &#39;that&#39;),\n (&#39;much&#39;, &#39;much&#39;, &#39;much&#39;, &#39;much&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;Lucas&#39;, &#39;Lucas&#39;, &#39;luca&#39;, &#39;Lucas&#39;),\n (&#39;Nogal&#39;, &#39;Nogal&#39;, &#39;nogal&#39;, &#39;Nogal&#39;),\n (&#39;Dunbercker&#39;, &#39;Dunbercker&#39;, &#39;dunberck&#39;, &#39;Dunbercker&#39;),\n (&#39;is&#39;, &#39;be&#39;, &#39;i&#39;, &#39;is&#39;),\n (&#39;no&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;),\n (&#39;longer&#39;, &#39;long&#39;, &#39;longer&#39;, &#39;longer&#39;),\n (&#39;happy&#39;, &#39;happy&#39;, &#39;happi&#39;, &#39;happy&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;He&#39;, &#39;He&#39;, &#39;he&#39;, &#39;He&#39;),\n (&#39;has&#39;, &#39;have&#39;, &#39;ha&#39;, &#39;has&#39;),\n (&#39;a&#39;, &#39;a&#39;, &#39;a&#39;, &#39;a&#39;),\n (&#39;good&#39;, &#39;good&#39;, &#39;good&#39;, &#39;good&#39;),\n (&#39;car&#39;, &#39;car&#39;, &#39;car&#39;, &#39;car&#39;),\n (&#39;though&#39;, &#39;though&#39;, &#39;though&#39;, &#39;though&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;Europe&#39;, &#39;Europe&#39;, &#39;europ&#39;, &#39;Europe&#39;),\n (&#39;is&#39;, &#39;be&#39;, &#39;i&#39;, &#39;is&#39;),\n (&#39;very&#39;, &#39;very&#39;, &#39;veri&#39;, &#39;very&#39;),\n (&#39;culture&#39;, &#39;culture&#39;, &#39;cultur&#39;, &#39;culture&#39;),\n (&#39;rich&#39;, &#39;rich&#39;, &#39;rich&#39;, &#39;rich&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;There&#39;, &#39;There&#39;, &#39;there&#39;, &#39;There&#39;),\n (&#39;are&#39;, &#39;be&#39;, &#39;ar&#39;, &#39;are&#39;),\n (&#39;huge&#39;, &#39;huge&#39;, &#39;huge&#39;, &#39;huge&#39;),\n (&#39;churches&#39;, &#39;church&#39;, &#39;church&#39;, &#39;churches&#39;),\n (&#39;!&#39;, &#39;!&#39;, &#39;!&#39;, &#39;!&#39;),\n (&#39;and&#39;, &#39;and&#39;, &#39;and&#39;, &#39;and&#39;),\n (&#39;big&#39;, &#39;big&#39;, &#39;big&#39;, &#39;big&#39;),\n (&#39;houses&#39;, &#39;house&#39;, &#39;hous&#39;, &#39;houses&#39;),\n (&#39;!&#39;, &#39;!&#39;, &#39;!&#39;, &#39;!&#39;)]</div>"]}}],"execution_count":23},{"cell_type":"code","source":["import pandas as pd\n\ndf = pd.DataFrame({'token':result['token'], \n                      'corrected':result['spell'], 'POS':result['pos'],\n                      'lemmas':result['lemmas'], 'stems':result['stems']})\ndf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","id":"0CiixcKhsQwa","outputId":"d66e52b1-64a8-4b3e-f719-dc8a5e09f144"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>corrected</th>\n      <th>POS</th>\n      <th>lemmas</th>\n      <th>stems</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter</td>\n      <td>Peter</td>\n      <td>NNP</td>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>very</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good</td>\n      <td>good</td>\n      <td>JJ</td>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>persn</td>\n      <td>person</td>\n      <td>NN</td>\n      <td>person</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>My</td>\n      <td>My</td>\n      <td>PRP$</td>\n      <td>My</td>\n      <td>my</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>life</td>\n      <td>life</td>\n      <td>NN</td>\n      <td>life</td>\n      <td>life</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>in</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>in</td>\n      <td>in</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Russia</td>\n      <td>Russia</td>\n      <td>NNP</td>\n      <td>Russia</td>\n      <td>russia</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>is</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>very</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>intersting</td>\n      <td>interesting</td>\n      <td>JJ</td>\n      <td>interest</td>\n      <td>interest</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>John</td>\n      <td>John</td>\n      <td>NNP</td>\n      <td>John</td>\n      <td>john</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>and</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>and</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Peter</td>\n      <td>Peter</td>\n      <td>NNP</td>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>are</td>\n      <td>are</td>\n      <td>VBP</td>\n      <td>be</td>\n      <td>ar</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>brothrs</td>\n      <td>broths</td>\n      <td>NNS</td>\n      <td>broth</td>\n      <td>broth</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>However</td>\n      <td>However</td>\n      <td>RB</td>\n      <td>However</td>\n      <td>howev</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>they</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>they</td>\n      <td>thei</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>don't</td>\n      <td>don't</td>\n      <td>VBP</td>\n      <td>don't</td>\n      <td>don't</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>support</td>\n      <td>support</td>\n      <td>VB</td>\n      <td>support</td>\n      <td>support</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>each</td>\n      <td>each</td>\n      <td>DT</td>\n      <td>each</td>\n      <td>each</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>other</td>\n      <td>other</td>\n      <td>JJ</td>\n      <td>other</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>that</td>\n      <td>that</td>\n      <td>IN</td>\n      <td>that</td>\n      <td>that</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>much</td>\n      <td>much</td>\n      <td>JJ</td>\n      <td>much</td>\n      <td>much</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Lucas</td>\n      <td>Lucas</td>\n      <td>NNP</td>\n      <td>Lucas</td>\n      <td>luca</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Nogal</td>\n      <td>Nogal</td>\n      <td>NNP</td>\n      <td>Nogal</td>\n      <td>nogal</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Dunbercker</td>\n      <td>Dunbercker</td>\n      <td>NNP</td>\n      <td>Dunbercker</td>\n      <td>dunberck</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>is</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>no</td>\n      <td>no</td>\n      <td>DT</td>\n      <td>no</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>longer</td>\n      <td>longer</td>\n      <td>RB</td>\n      <td>long</td>\n      <td>longer</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>happy</td>\n      <td>happy</td>\n      <td>JJ</td>\n      <td>happy</td>\n      <td>happi</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>He</td>\n      <td>He</td>\n      <td>PRP</td>\n      <td>He</td>\n      <td>he</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>has</td>\n      <td>has</td>\n      <td>VBZ</td>\n      <td>have</td>\n      <td>ha</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>a</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>good</td>\n      <td>good</td>\n      <td>JJ</td>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>car</td>\n      <td>car</td>\n      <td>NN</td>\n      <td>car</td>\n      <td>car</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>though</td>\n      <td>though</td>\n      <td>IN</td>\n      <td>though</td>\n      <td>though</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Europe</td>\n      <td>Europe</td>\n      <td>NNP</td>\n      <td>Europe</td>\n      <td>europ</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>is</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>very</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>culture</td>\n      <td>culture</td>\n      <td>RB</td>\n      <td>culture</td>\n      <td>cultur</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>rich</td>\n      <td>rich</td>\n      <td>JJ</td>\n      <td>rich</td>\n      <td>rich</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>There</td>\n      <td>There</td>\n      <td>EX</td>\n      <td>There</td>\n      <td>there</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>are</td>\n      <td>are</td>\n      <td>VBP</td>\n      <td>be</td>\n      <td>ar</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>huge</td>\n      <td>huge</td>\n      <td>JJ</td>\n      <td>huge</td>\n      <td>huge</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>churches</td>\n      <td>churches</td>\n      <td>NNS</td>\n      <td>church</td>\n      <td>church</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>!</td>\n      <td>!</td>\n      <td>.</td>\n      <td>!</td>\n      <td>!</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>and</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>and</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>big</td>\n      <td>big</td>\n      <td>JJ</td>\n      <td>big</td>\n      <td>big</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>houses</td>\n      <td>houses</td>\n      <td>NNS</td>\n      <td>house</td>\n      <td>hous</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>!</td>\n      <td>!</td>\n      <td>.</td>\n      <td>!</td>\n      <td>!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["### Explain Document DL"],"metadata":{"colab_type":"text","id":"xoNLwohgvD7L"}},{"cell_type":"markdown","source":["### Recognize Entities DL"],"metadata":{}},{"cell_type":"code","source":["recognize_entities = PretrainedPipeline('recognize_entities_dl', lang='en')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">recognize_entities_dl download started this may take some time.\nApprox size to download 159 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[OK!]\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["testDoc = '''\nPeter is a very good persn.\nMy life in Russia is very intersting.\nJohn and Peter are brothrs. However they don't support each other that much.\nLucas Nogal Dunbercker is no longer happy. He has a good car though.\nEurope is very culture rich. There are huge churches! and big houses!\n'''\n\nresult = recognize_entities.annotate(testDoc)\n\nlist(zip(result['token'], result['ner']))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[43]: [(&#39;Peter&#39;, &#39;B-PER&#39;),\n (&#39;is&#39;, &#39;O&#39;),\n (&#39;a&#39;, &#39;O&#39;),\n (&#39;very&#39;, &#39;O&#39;),\n (&#39;good&#39;, &#39;O&#39;),\n (&#39;persn&#39;, &#39;O&#39;),\n (&#39;.&#39;, &#39;O&#39;),\n (&#39;My&#39;, &#39;O&#39;),\n (&#39;life&#39;, &#39;O&#39;),\n (&#39;in&#39;, &#39;O&#39;),\n (&#39;Russia&#39;, &#39;B-LOC&#39;),\n (&#39;is&#39;, &#39;O&#39;),\n (&#39;very&#39;, &#39;O&#39;),\n (&#39;intersting&#39;, &#39;O&#39;),\n (&#39;.&#39;, &#39;O&#39;),\n (&#39;John&#39;, &#39;B-PER&#39;),\n (&#39;and&#39;, &#39;O&#39;),\n (&#39;Peter&#39;, &#39;B-PER&#39;),\n (&#39;are&#39;, &#39;O&#39;),\n (&#39;brothrs&#39;, &#39;O&#39;),\n (&#39;.&#39;, &#39;O&#39;),\n (&#39;However&#39;, &#39;O&#39;),\n (&#39;they&#39;, &#39;O&#39;),\n (&#34;don&#39;t&#34;, &#39;O&#39;),\n (&#39;support&#39;, &#39;O&#39;),\n (&#39;each&#39;, &#39;O&#39;),\n (&#39;other&#39;, &#39;O&#39;),\n (&#39;that&#39;, &#39;O&#39;),\n (&#39;much&#39;, &#39;O&#39;),\n (&#39;.&#39;, &#39;O&#39;),\n (&#39;Lucas&#39;, &#39;B-ORG&#39;),\n (&#39;Nogal&#39;, &#39;I-ORG&#39;),\n (&#39;Dunbercker&#39;, &#39;I-ORG&#39;),\n (&#39;is&#39;, &#39;O&#39;),\n (&#39;no&#39;, &#39;O&#39;),\n (&#39;longer&#39;, &#39;O&#39;),\n (&#39;happy&#39;, &#39;O&#39;),\n (&#39;.&#39;, &#39;O&#39;),\n (&#39;He&#39;, &#39;O&#39;),\n (&#39;has&#39;, &#39;O&#39;),\n (&#39;a&#39;, &#39;O&#39;),\n (&#39;good&#39;, &#39;O&#39;),\n (&#39;car&#39;, &#39;O&#39;),\n (&#39;though&#39;, &#39;O&#39;),\n (&#39;.&#39;, &#39;O&#39;),\n (&#39;Europe&#39;, &#39;B-LOC&#39;),\n (&#39;is&#39;, &#39;O&#39;),\n (&#39;very&#39;, &#39;O&#39;),\n (&#39;culture&#39;, &#39;O&#39;),\n (&#39;rich&#39;, &#39;O&#39;),\n (&#39;.&#39;, &#39;O&#39;),\n (&#39;There&#39;, &#39;O&#39;),\n (&#39;are&#39;, &#39;O&#39;),\n (&#39;huge&#39;, &#39;O&#39;),\n (&#39;churches&#39;, &#39;O&#39;),\n (&#39;!&#39;, &#39;O&#39;),\n (&#39;and&#39;, &#39;O&#39;),\n (&#39;big&#39;, &#39;O&#39;),\n (&#39;houses&#39;, &#39;O&#39;),\n (&#39;!&#39;, &#39;O&#39;)]</div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["### Clean Stop Words"],"metadata":{}},{"cell_type":"code","source":["clean_stop = PretrainedPipeline('clean_stop', lang='en')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">clean_stop download started this may take some time.\nApprox size to download 12.4 KB\n\r[ | ]\r[ / ]\r[OK!]\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["result = clean_stop.annotate(testDoc)\n\n' '.join(result['cleanTokens'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[45]: &#34;Peter good persn . life Russia intersting . John Peter brothrs . don&#39;t support . Lucas Nogal Dunbercker longer happy . good car . Europe culture rich . huge churches ! big houses !&#34;</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["### Clean Slang"],"metadata":{}},{"cell_type":"code","source":["clean_slang = PretrainedPipeline('clean_slang', lang='en')\n\nresult = clean_slang.annotate(' Whatsup bro, call me ASAP')\n\n' '.join(result['normal'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">clean_slang download started this may take some time.\nApprox size to download 21.8 KB\n\r[ | ]\r[ / ]\r[OK!]\nOut[46]: &#39;how are you friend call me as soon as possible&#39;</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["**Stages**\n- DocumentAssembler\n- SentenceDetector\n- Tokenizer\n- NER (NER with GloVe, CoNLL2003 dataset)\n- Lemmatizer\n- Stemmer\n- Part of Speech\n- SpellChecker (Norvig)"],"metadata":{"colab_type":"text","id":"IdsQHjKHwSpH"}},{"cell_type":"code","source":["pipeline_dl = PretrainedPipeline('explain_document_dl', lang='en')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"wPxRk5SzsumW","outputId":"f456e7bf-ad47-488d-8dca-01d2ae8d9305"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">explain_document_dl download started this may take some time.\nApprox size to download 168.4 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[OK!]\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["result = pipeline_dl.annotate(testDoc)\n\nresult.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"colab_type":"code","id":"NLTBkfC5vKSa","outputId":"c2ee0ffc-16da-4c8b-8070-4fc104a466d5"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[48]: dict_keys([&#39;entities&#39;, &#39;stem&#39;, &#39;checked&#39;, &#39;lemma&#39;, &#39;document&#39;, &#39;pos&#39;, &#39;token&#39;, &#39;ner&#39;, &#39;embeddings&#39;, &#39;sentence&#39;])</div>"]}}],"execution_count":36},{"cell_type":"code","source":["result['entities']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"4UrimwRVxRUh","outputId":"1d350fc8-9e2c-43d4-f19b-bf9109d3c14a"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[49]: [&#39;Peter&#39;, &#39;Russia&#39;, &#39;John&#39;, &#39;Peter&#39;, &#39;Lucas Nogal Dunbercker&#39;, &#39;Europe&#39;]</div>"]}}],"execution_count":37},{"cell_type":"code","source":["df = pd.DataFrame({'token':result['token'], 'ner_label':result['ner'],\n                      'spell_corrected':result['checked'], 'POS':result['pos'],\n                      'lemmas':result['lemma'], 'stems':result['stem']})\n\ndf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","id":"pRI8vqdcv4Ui","outputId":"8f5c8ef6-462e-45c0-8921-bad4485183a2"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>ner_label</th>\n      <th>spell_corrected</th>\n      <th>POS</th>\n      <th>lemmas</th>\n      <th>stems</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter</td>\n      <td>B-PER</td>\n      <td>Peter</td>\n      <td>NNP</td>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>O</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good</td>\n      <td>O</td>\n      <td>good</td>\n      <td>JJ</td>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>persn</td>\n      <td>O</td>\n      <td>person</td>\n      <td>NN</td>\n      <td>person</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>My</td>\n      <td>O</td>\n      <td>My</td>\n      <td>PRP$</td>\n      <td>My</td>\n      <td>my</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>life</td>\n      <td>O</td>\n      <td>life</td>\n      <td>NN</td>\n      <td>life</td>\n      <td>life</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>in</td>\n      <td>O</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>in</td>\n      <td>in</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Russia</td>\n      <td>B-LOC</td>\n      <td>Russia</td>\n      <td>NNP</td>\n      <td>Russia</td>\n      <td>russia</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>intersting</td>\n      <td>O</td>\n      <td>interesting</td>\n      <td>JJ</td>\n      <td>interest</td>\n      <td>interest</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>John</td>\n      <td>B-PER</td>\n      <td>John</td>\n      <td>NNP</td>\n      <td>John</td>\n      <td>john</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>and</td>\n      <td>O</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>and</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Peter</td>\n      <td>B-PER</td>\n      <td>Peter</td>\n      <td>NNP</td>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>are</td>\n      <td>O</td>\n      <td>are</td>\n      <td>VBP</td>\n      <td>be</td>\n      <td>ar</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>brothrs</td>\n      <td>O</td>\n      <td>broths</td>\n      <td>NNS</td>\n      <td>broth</td>\n      <td>broth</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>However</td>\n      <td>O</td>\n      <td>However</td>\n      <td>RB</td>\n      <td>However</td>\n      <td>howev</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>they</td>\n      <td>O</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>they</td>\n      <td>thei</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>don't</td>\n      <td>O</td>\n      <td>don't</td>\n      <td>VBP</td>\n      <td>don't</td>\n      <td>don't</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>support</td>\n      <td>O</td>\n      <td>support</td>\n      <td>VB</td>\n      <td>support</td>\n      <td>support</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>each</td>\n      <td>O</td>\n      <td>each</td>\n      <td>DT</td>\n      <td>each</td>\n      <td>each</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>other</td>\n      <td>O</td>\n      <td>other</td>\n      <td>JJ</td>\n      <td>other</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>that</td>\n      <td>O</td>\n      <td>that</td>\n      <td>IN</td>\n      <td>that</td>\n      <td>that</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>much</td>\n      <td>O</td>\n      <td>much</td>\n      <td>JJ</td>\n      <td>much</td>\n      <td>much</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Lucas</td>\n      <td>B-ORG</td>\n      <td>Lucas</td>\n      <td>NNP</td>\n      <td>Lucas</td>\n      <td>luca</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Nogal</td>\n      <td>I-ORG</td>\n      <td>Nogal</td>\n      <td>NNP</td>\n      <td>Nogal</td>\n      <td>nogal</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Dunbercker</td>\n      <td>I-ORG</td>\n      <td>Dunbercker</td>\n      <td>NNP</td>\n      <td>Dunbercker</td>\n      <td>dunberck</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>no</td>\n      <td>O</td>\n      <td>no</td>\n      <td>DT</td>\n      <td>no</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>longer</td>\n      <td>O</td>\n      <td>longer</td>\n      <td>RB</td>\n      <td>long</td>\n      <td>longer</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>happy</td>\n      <td>O</td>\n      <td>happy</td>\n      <td>JJ</td>\n      <td>happy</td>\n      <td>happi</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>He</td>\n      <td>O</td>\n      <td>He</td>\n      <td>PRP</td>\n      <td>He</td>\n      <td>he</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>has</td>\n      <td>O</td>\n      <td>has</td>\n      <td>VBZ</td>\n      <td>have</td>\n      <td>ha</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>a</td>\n      <td>O</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>good</td>\n      <td>O</td>\n      <td>good</td>\n      <td>JJ</td>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>car</td>\n      <td>O</td>\n      <td>car</td>\n      <td>NN</td>\n      <td>car</td>\n      <td>car</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>though</td>\n      <td>O</td>\n      <td>though</td>\n      <td>IN</td>\n      <td>though</td>\n      <td>though</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Europe</td>\n      <td>B-LOC</td>\n      <td>Europe</td>\n      <td>NNP</td>\n      <td>Europe</td>\n      <td>europ</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>culture</td>\n      <td>O</td>\n      <td>culture</td>\n      <td>RB</td>\n      <td>culture</td>\n      <td>cultur</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>rich</td>\n      <td>O</td>\n      <td>rich</td>\n      <td>JJ</td>\n      <td>rich</td>\n      <td>rich</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>There</td>\n      <td>O</td>\n      <td>There</td>\n      <td>EX</td>\n      <td>There</td>\n      <td>there</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>are</td>\n      <td>O</td>\n      <td>are</td>\n      <td>VBP</td>\n      <td>be</td>\n      <td>ar</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>huge</td>\n      <td>O</td>\n      <td>huge</td>\n      <td>JJ</td>\n      <td>huge</td>\n      <td>huge</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>churches</td>\n      <td>O</td>\n      <td>churches</td>\n      <td>NNS</td>\n      <td>church</td>\n      <td>church</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>!</td>\n      <td>O</td>\n      <td>!</td>\n      <td>.</td>\n      <td>!</td>\n      <td>!</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>and</td>\n      <td>O</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>and</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>big</td>\n      <td>O</td>\n      <td>big</td>\n      <td>JJ</td>\n      <td>big</td>\n      <td>big</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>houses</td>\n      <td>O</td>\n      <td>houses</td>\n      <td>NNS</td>\n      <td>house</td>\n      <td>hous</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>!</td>\n      <td>O</td>\n      <td>!</td>\n      <td>.</td>\n      <td>!</td>\n      <td>!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["### Spell Checker"],"metadata":{"colab_type":"text","id":"2jIY9tiRxxxh"}},{"cell_type":"code","source":["spell_checker = PretrainedPipeline('check_spelling', lang='en')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"oHmbaOUJxsnk","outputId":"28bf511c-b777-4f5e-d7a0-430d0966ea80"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">check_spelling download started this may take some time.\nApprox size to download 892.6 KB\n\r[ | ]\r[ / ]\r[OK!]\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["result = spell_checker.annotate(testDoc)\n\nresult.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"qcbyRyG4yMxV","outputId":"6914a8fc-d96a-4850-d30c-bf51639fbe1d"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[52]: dict_keys([&#39;document&#39;, &#39;sentence&#39;, &#39;token&#39;, &#39;checked&#39;])</div>"]}}],"execution_count":41},{"cell_type":"code","source":["list(zip(result['token'], result['checked']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":710},"colab_type":"code","id":"KJuhnR2MyPYq","outputId":"917344fd-5e70-40af-fc02-48d6aa3890cc"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[53]: [(&#39;Peter&#39;, &#39;Peter&#39;),\n (&#39;is&#39;, &#39;is&#39;),\n (&#39;a&#39;, &#39;a&#39;),\n (&#39;very&#39;, &#39;very&#39;),\n (&#39;good&#39;, &#39;good&#39;),\n (&#39;persn&#39;, &#39;person&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;My&#39;, &#39;My&#39;),\n (&#39;life&#39;, &#39;life&#39;),\n (&#39;in&#39;, &#39;in&#39;),\n (&#39;Russia&#39;, &#39;Russia&#39;),\n (&#39;is&#39;, &#39;is&#39;),\n (&#39;very&#39;, &#39;very&#39;),\n (&#39;intersting&#39;, &#39;interesting&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;John&#39;, &#39;John&#39;),\n (&#39;and&#39;, &#39;and&#39;),\n (&#39;Peter&#39;, &#39;Peter&#39;),\n (&#39;are&#39;, &#39;are&#39;),\n (&#39;brothrs&#39;, &#39;brothers&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;However&#39;, &#39;However&#39;),\n (&#39;they&#39;, &#39;they&#39;),\n (&#34;don&#39;t&#34;, &#34;don&#39;t&#34;),\n (&#39;support&#39;, &#39;support&#39;),\n (&#39;each&#39;, &#39;each&#39;),\n (&#39;other&#39;, &#39;other&#39;),\n (&#39;that&#39;, &#39;that&#39;),\n (&#39;much&#39;, &#39;much&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;Lucas&#39;, &#39;Lucas&#39;),\n (&#39;Nogal&#39;, &#39;Nigel&#39;),\n (&#39;Dunbercker&#39;, &#39;Dunbercker&#39;),\n (&#39;is&#39;, &#39;is&#39;),\n (&#39;no&#39;, &#39;no&#39;),\n (&#39;longer&#39;, &#39;longer&#39;),\n (&#39;happy&#39;, &#39;happy&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;He&#39;, &#39;He&#39;),\n (&#39;has&#39;, &#39;has&#39;),\n (&#39;a&#39;, &#39;a&#39;),\n (&#39;good&#39;, &#39;good&#39;),\n (&#39;car&#39;, &#39;car&#39;),\n (&#39;though&#39;, &#39;though&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;Europe&#39;, &#39;Europe&#39;),\n (&#39;is&#39;, &#39;is&#39;),\n (&#39;very&#39;, &#39;very&#39;),\n (&#39;culture&#39;, &#39;culture&#39;),\n (&#39;rich&#39;, &#39;rich&#39;),\n (&#39;.&#39;, &#39;.&#39;),\n (&#39;There&#39;, &#39;There&#39;),\n (&#39;are&#39;, &#39;are&#39;),\n (&#39;huge&#39;, &#39;huge&#39;),\n (&#39;churches&#39;, &#39;churches&#39;),\n (&#39;!&#39;, &#39;!&#39;),\n (&#39;and&#39;, &#39;and&#39;),\n (&#39;big&#39;, &#39;big&#39;),\n (&#39;houses&#39;, &#39;houses&#39;),\n (&#39;!&#39;, &#39;!&#39;)]</div>"]}}],"execution_count":42},{"cell_type":"markdown","source":["### Spell Checker DL\nhttps://medium.com/spark-nlp/applying-context-aware-spell-checking-in-spark-nlp-3c29c46963bc"],"metadata":{}},{"cell_type":"code","source":["spell_checker_dl = PretrainedPipeline('check_spelling_dl', lang='en')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">check_spelling_dl download started this may take some time.\nApprox size to download 112.1 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[OK!]\n</div>"]}}],"execution_count":44},{"cell_type":"code","source":["text = 'We will go to swimming if the ueather is nice.'\n\nresult = spell_checker_dl.annotate(text)\n\nlist(zip(result['token'], result['checked']))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[55]: [(&#39;We&#39;, &#39;We&#39;),\n (&#39;will&#39;, &#39;will&#39;),\n (&#39;go&#39;, &#39;go&#39;),\n (&#39;to&#39;, &#39;to&#39;),\n (&#39;swimming&#39;, &#39;swimming&#39;),\n (&#39;if&#39;, &#39;if&#39;),\n (&#39;the&#39;, &#39;the&#39;),\n (&#39;ueather&#39;, &#39;weather&#39;),\n (&#39;is&#39;, &#39;is&#39;),\n (&#39;nice&#39;, &#39;nice&#39;),\n (&#39;.&#39;, &#39;.&#39;)]</div>"]}}],"execution_count":45},{"cell_type":"code","source":["result.keys()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[56]: dict_keys([&#39;document&#39;, &#39;sentence&#39;, &#39;token&#39;, &#39;checked&#39;])</div>"]}}],"execution_count":46},{"cell_type":"code","source":["# check for the different occurrences of the word \"ueather\"\nexamples = ['We will go to swimming if the ueather is nice.',\\\n    \"I have a black ueather jacket, so nice.\",\\\n    \"I introduce you to my sister, she is called ueather.\"]\n\nresults = spell_checker_dl.annotate(examples)\n\nfor result in results:\n  print (list(zip(result['token'], result['checked'])))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;We&#39;, &#39;We&#39;), (&#39;will&#39;, &#39;will&#39;), (&#39;go&#39;, &#39;go&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;swimming&#39;, &#39;swimming&#39;), (&#39;if&#39;, &#39;if&#39;), (&#39;the&#39;, &#39;the&#39;), (&#39;ueather&#39;, &#39;weather&#39;), (&#39;is&#39;, &#39;is&#39;), (&#39;nice&#39;, &#39;nice&#39;), (&#39;.&#39;, &#39;.&#39;)]\n[(&#39;I&#39;, &#39;I&#39;), (&#39;have&#39;, &#39;have&#39;), (&#39;a&#39;, &#39;a&#39;), (&#39;black&#39;, &#39;black&#39;), (&#39;ueather&#39;, &#39;leather&#39;), (&#39;jacket&#39;, &#39;jacket&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;so&#39;, &#39;so&#39;), (&#39;nice&#39;, &#39;nice&#39;), (&#39;.&#39;, &#39;.&#39;)]\n[(&#39;I&#39;, &#39;I&#39;), (&#39;introduce&#39;, &#39;introduce&#39;), (&#39;you&#39;, &#39;you&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;my&#39;, &#39;my&#39;), (&#39;sister&#39;, &#39;sister&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;she&#39;, &#39;she&#39;), (&#39;is&#39;, &#39;is&#39;), (&#39;called&#39;, &#39;called&#39;), (&#39;ueather&#39;, &#39;Heather&#39;), (&#39;.&#39;, &#39;.&#39;)]\n</div>"]}}],"execution_count":47},{"cell_type":"code","source":["for result in results:\n  print (result['document'],'>>',[pairs for pairs in list(zip(result['token'], result['checked'])) if pairs[0]!=pairs[1]])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;We will go to swimming if the ueather is nice.&#39;] &gt;&gt; [(&#39;ueather&#39;, &#39;weather&#39;)]\n[&#39;I have a black ueather jacket, so nice.&#39;] &gt;&gt; [(&#39;ueather&#39;, &#39;leather&#39;)]\n[&#39;I introduce you to my sister, she is called ueather.&#39;] &gt;&gt; [(&#39;ueather&#39;, &#39;Heather&#39;)]\n</div>"]}}],"execution_count":48},{"cell_type":"code","source":["# if we had tried the same with spell_checker (previous version)\n\nresults = spell_checker.annotate(examples)\n\nfor result in results:\n  print (list(zip(result['token'], result['checked'])))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;We&#39;, &#39;We&#39;), (&#39;will&#39;, &#39;will&#39;), (&#39;go&#39;, &#39;go&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;swimming&#39;, &#39;swimming&#39;), (&#39;if&#39;, &#39;if&#39;), (&#39;the&#39;, &#39;the&#39;), (&#39;ueather&#39;, &#39;weather&#39;), (&#39;is&#39;, &#39;is&#39;), (&#39;nice&#39;, &#39;nice&#39;), (&#39;.&#39;, &#39;.&#39;)]\n[(&#39;I&#39;, &#39;I&#39;), (&#39;have&#39;, &#39;have&#39;), (&#39;a&#39;, &#39;a&#39;), (&#39;black&#39;, &#39;black&#39;), (&#39;ueather&#39;, &#39;weather&#39;), (&#39;jacket&#39;, &#39;jacket&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;so&#39;, &#39;so&#39;), (&#39;nice&#39;, &#39;nice&#39;), (&#39;.&#39;, &#39;.&#39;)]\n[(&#39;I&#39;, &#39;I&#39;), (&#39;introduce&#39;, &#39;introduce&#39;), (&#39;you&#39;, &#39;you&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;my&#39;, &#39;my&#39;), (&#39;sister&#39;, &#39;sister&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;she&#39;, &#39;she&#39;), (&#39;is&#39;, &#39;is&#39;), (&#39;called&#39;, &#39;called&#39;), (&#39;ueather&#39;, &#39;weather&#39;), (&#39;.&#39;, &#39;.&#39;)]\n</div>"]}}],"execution_count":49},{"cell_type":"markdown","source":["### Parsing a list of texts"],"metadata":{"colab_type":"text","id":"7-GIZT52zDqO"}},{"cell_type":"code","source":["testDoc_list = ['French author who helped pioner the science-fiction genre.',\n'Verne wrate about space, air, and underwater travel before navigable aircrast',\n'Practical submarines were invented, and before any means of space travel had been devised.']\n\ntestDoc_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"wcXYwNndzJWb","outputId":"32da3f38-02f9-4ce6-9d54-1ed07234f355"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[60]: [&#39;French author who helped pioner the science-fiction genre.&#39;,\n &#39;Verne wrate about space, air, and underwater travel before navigable aircrast&#39;,\n &#39;Practical submarines were invented, and before any means of space travel had been devised.&#39;]</div>"]}}],"execution_count":51},{"cell_type":"code","source":["result_list = pipeline.annotate(testDoc_list)\n\nlen (result_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"Yzegl_OEzbMi","outputId":"8c66f374-9997-4c87-ea02-aedd5fe2b66e"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[61]: 3</div>"]}}],"execution_count":52},{"cell_type":"code","source":["result_list[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":710},"colab_type":"code","id":"sf0Uzm9yzmNV","outputId":"01ffcda5-c127-47de-e11b-1621ac04f3c2"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[62]: {&#39;document&#39;: [&#39;French author who helped pioner the science-fiction genre.&#39;],\n &#39;spell&#39;: [&#39;French&#39;,\n  &#39;author&#39;,\n  &#39;who&#39;,\n  &#39;helped&#39;,\n  &#39;pioneer&#39;,\n  &#39;the&#39;,\n  &#39;sciencefiction&#39;,\n  &#39;genre&#39;,\n  &#39;.&#39;],\n &#39;pos&#39;: [&#39;JJ&#39;, &#39;NN&#39;, &#39;WP&#39;, &#39;VBD&#39;, &#39;NN&#39;, &#39;DT&#39;, &#39;NN&#39;, &#39;NN&#39;, &#39;.&#39;],\n &#39;lemmas&#39;: [&#39;French&#39;,\n  &#39;author&#39;,\n  &#39;who&#39;,\n  &#39;help&#39;,\n  &#39;pioneer&#39;,\n  &#39;the&#39;,\n  &#39;sciencefiction&#39;,\n  &#39;genre&#39;,\n  &#39;.&#39;],\n &#39;token&#39;: [&#39;French&#39;,\n  &#39;author&#39;,\n  &#39;who&#39;,\n  &#39;helped&#39;,\n  &#39;pioner&#39;,\n  &#39;the&#39;,\n  &#39;science-fiction&#39;,\n  &#39;genre&#39;,\n  &#39;.&#39;],\n &#39;stems&#39;: [&#39;french&#39;,\n  &#39;author&#39;,\n  &#39;who&#39;,\n  &#39;help&#39;,\n  &#39;pioneer&#39;,\n  &#39;the&#39;,\n  &#39;sciencefict&#39;,\n  &#39;genr&#39;,\n  &#39;.&#39;],\n &#39;sentence&#39;: [&#39;French author who helped pioner the science-fiction genre.&#39;]}</div>"]}}],"execution_count":53},{"cell_type":"markdown","source":["### Using fullAnnotate to get more details"],"metadata":{"colab_type":"text","id":"EqLsubshycBo"}},{"cell_type":"code","source":["text = 'Peter Parker is a nice guy and lives in New York'"],"metadata":{"colab":{},"colab_type":"code","id":"9EvvLmUlyXLs"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":55},{"cell_type":"code","source":["# pipeline_dl >> explain_document_dl\n\ndetailed_result = pipeline_dl.fullAnnotate(text)"],"metadata":{"colab":{},"colab_type":"code","id":"pg0nU5hOxcCt"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":56},{"cell_type":"code","source":["detailed_result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","id":"3fPAdbZTxfXD","outputId":"b54a756b-928c-4d6d-fa08-ac2566231558"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[65]: [{&#39;entities&#39;: [Annotation(chunk, 0, 11, Peter Parker, {&#39;entity&#39;: &#39;PER&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;0&#39;}),\n   Annotation(chunk, 40, 47, New York, {&#39;entity&#39;: &#39;LOC&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;1&#39;})],\n  &#39;stem&#39;: [Annotation(token, 0, 4, peter, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 6, 11, parker, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 13, 14, i, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 16, 16, a, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 18, 21, nice, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 23, 25, gui, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 29, and, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 31, 35, live, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 38, in, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 40, 42, new, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 44, 47, york, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;})],\n  &#39;checked&#39;: [Annotation(token, 0, 4, Peter, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 6, 11, Parker, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 13, 14, is, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 16, 16, a, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 18, 21, nice, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 23, 25, guy, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 29, and, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 31, 35, lives, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 38, in, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 40, 42, New, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 44, 47, York, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;})],\n  &#39;lemma&#39;: [Annotation(token, 0, 4, Peter, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 6, 11, Parker, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 13, 14, be, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 16, 16, a, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 18, 21, nice, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 23, 25, guy, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 29, and, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 31, 35, life, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 38, in, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 40, 42, New, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 44, 47, York, {&#39;confidence&#39;: &#39;1.0&#39;, &#39;sentence&#39;: &#39;0&#39;})],\n  &#39;document&#39;: [Annotation(document, 0, 47, Peter Parker is a nice guy and lives in New York, {})],\n  &#39;pos&#39;: [Annotation(pos, 0, 4, NNP, {&#39;word&#39;: &#39;Peter&#39;}),\n   Annotation(pos, 6, 11, NNP, {&#39;word&#39;: &#39;Parker&#39;}),\n   Annotation(pos, 13, 14, VBZ, {&#39;word&#39;: &#39;is&#39;}),\n   Annotation(pos, 16, 16, DT, {&#39;word&#39;: &#39;a&#39;}),\n   Annotation(pos, 18, 21, JJ, {&#39;word&#39;: &#39;nice&#39;}),\n   Annotation(pos, 23, 25, NN, {&#39;word&#39;: &#39;guy&#39;}),\n   Annotation(pos, 27, 29, CC, {&#39;word&#39;: &#39;and&#39;}),\n   Annotation(pos, 31, 35, NNS, {&#39;word&#39;: &#39;lives&#39;}),\n   Annotation(pos, 37, 38, IN, {&#39;word&#39;: &#39;in&#39;}),\n   Annotation(pos, 40, 42, NNP, {&#39;word&#39;: &#39;New&#39;}),\n   Annotation(pos, 44, 47, NNP, {&#39;word&#39;: &#39;York&#39;})],\n  &#39;token&#39;: [Annotation(token, 0, 4, Peter, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 6, 11, Parker, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 13, 14, is, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 16, 16, a, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 18, 21, nice, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 23, 25, guy, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 29, and, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 31, 35, lives, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 38, in, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 40, 42, New, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 44, 47, York, {&#39;sentence&#39;: &#39;0&#39;})],\n  &#39;ner&#39;: [Annotation(named_entity, 0, 4, B-PER, {&#39;word&#39;: &#39;Peter&#39;}),\n   Annotation(named_entity, 6, 11, I-PER, {&#39;word&#39;: &#39;Parker&#39;}),\n   Annotation(named_entity, 13, 14, O, {&#39;word&#39;: &#39;is&#39;}),\n   Annotation(named_entity, 16, 16, O, {&#39;word&#39;: &#39;a&#39;}),\n   Annotation(named_entity, 18, 21, O, {&#39;word&#39;: &#39;nice&#39;}),\n   Annotation(named_entity, 23, 25, O, {&#39;word&#39;: &#39;guy&#39;}),\n   Annotation(named_entity, 27, 29, O, {&#39;word&#39;: &#39;and&#39;}),\n   Annotation(named_entity, 31, 35, O, {&#39;word&#39;: &#39;lives&#39;}),\n   Annotation(named_entity, 37, 38, O, {&#39;word&#39;: &#39;in&#39;}),\n   Annotation(named_entity, 40, 42, B-LOC, {&#39;word&#39;: &#39;New&#39;}),\n   Annotation(named_entity, 44, 47, I-LOC, {&#39;word&#39;: &#39;York&#39;})],\n  &#39;embeddings&#39;: [Annotation(word_embeddings, 0, 4, Peter, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;Peter&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 6, 11, Parker, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;Parker&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 13, 14, is, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;is&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 16, 16, a, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;a&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 18, 21, nice, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;nice&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 23, 25, guy, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;guy&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 27, 29, and, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;and&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 31, 35, lives, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;lives&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 37, 38, in, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;in&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 40, 42, New, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;New&#39;, &#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(word_embeddings, 44, 47, York, {&#39;isOOV&#39;: &#39;false&#39;, &#39;pieceId&#39;: &#39;-1&#39;, &#39;isWordStart&#39;: &#39;true&#39;, &#39;token&#39;: &#39;York&#39;, &#39;sentence&#39;: &#39;0&#39;})],\n  &#39;sentence&#39;: [Annotation(document, 0, 47, Peter Parker is a nice guy and lives in New York, {&#39;sentence&#39;: &#39;0&#39;})]}]</div>"]}}],"execution_count":57},{"cell_type":"code","source":[""],"metadata":{"colab":{},"colab_type":"code","id":"GXkhtCdJ0VgV"},"outputs":[],"execution_count":58},{"cell_type":"code","source":["detailed_result[0]['entities']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"colab_type":"code","id":"OtvDDG560_Dx","outputId":"460c89ec-72a0-49bb-f9fb-f4ff5fed2262"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[66]: [Annotation(chunk, 0, 11, Peter Parker, {&#39;entity&#39;: &#39;PER&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;0&#39;}),\n Annotation(chunk, 40, 47, New York, {&#39;entity&#39;: &#39;LOC&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;1&#39;})]</div>"]}}],"execution_count":59},{"cell_type":"code","source":["chunks=[]\nentities=[]\nfor n in detailed_result[0]['entities']:\n        \n  chunks.append(n.result)\n  entities.append(n.metadata['entity']) \n    \ndf = pd.DataFrame({'chunks':chunks, 'entities':entities})\ndf    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"colab_type":"code","id":"czqRRv-7wHpO","outputId":"4646df73-469e-4d6d-a7f1-dab2382375ee"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter Parker</td>\n      <td>PER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>New York</td>\n      <td>LOC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":60},{"cell_type":"code","source":["tuples = []\n\nfor x,y,z in zip(detailed_result[0][\"token\"], detailed_result[0][\"pos\"], detailed_result[0][\"ner\"]):\n\n  tuples.append((int(x.metadata['sentence']), x.result, x.begin, x.end, y.result, z.result))\n\ndf = pd.DataFrame(tuples, columns=['sent_id','token','start','end','pos', 'ner'])\n\ndf\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"colab_type":"code","id":"8KIyPi5O0nvT","outputId":"cfd8878c-6496-48fb-a8af-7493be96510e"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_id</th>\n      <th>token</th>\n      <th>start</th>\n      <th>end</th>\n      <th>pos</th>\n      <th>ner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Peter</td>\n      <td>0</td>\n      <td>4</td>\n      <td>NNP</td>\n      <td>B-PER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Parker</td>\n      <td>6</td>\n      <td>11</td>\n      <td>NNP</td>\n      <td>I-PER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>is</td>\n      <td>13</td>\n      <td>14</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>a</td>\n      <td>16</td>\n      <td>16</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>nice</td>\n      <td>18</td>\n      <td>21</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>guy</td>\n      <td>23</td>\n      <td>25</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>and</td>\n      <td>27</td>\n      <td>29</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>lives</td>\n      <td>31</td>\n      <td>35</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>in</td>\n      <td>37</td>\n      <td>38</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>New</td>\n      <td>40</td>\n      <td>42</td>\n      <td>NNP</td>\n      <td>B-LOC</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>York</td>\n      <td>44</td>\n      <td>47</td>\n      <td>NNP</td>\n      <td>I-LOC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":61},{"cell_type":"markdown","source":["### Use pretrained match_chunk Pipeline for Individual Noun Phrase"],"metadata":{"colab_type":"text","id":"X7ZXnJGq2vAA"}},{"cell_type":"markdown","source":["**Stages**\n- DocumentAssembler\n- SentenceDetector\n- Tokenizer\n- Part of Speech\n- Chunker\n\nPipeline:\n\n- The pipeline uses regex `<DT>?<JJ>*<NN>+`\n- which states that whenever the chunk finds an optional determiner (DT) followed by any number of adjectives (JJ) and then a noun (NN) then the Noun Phrase(NP) chunk should be formed."],"metadata":{"colab_type":"text","id":"robP3BIy23So"}},{"cell_type":"code","source":["pipeline = PretrainedPipeline('match_chunks', lang='en')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"cMNVe5Cx2A-V","outputId":"289dee17-dda6-4b43-8e57-8de0c9f0bf89"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">match_chunks download started this may take some time.\nApprox size to download 4.3 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[OK!]\n</div>"]}}],"execution_count":64},{"cell_type":"code","source":["result = pipeline.annotate(\"The book has many chapters\") # single noun phrase\n"],"metadata":{"colab":{},"colab_type":"code","id":"CH0lmriN3cm-"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":65},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"colab_type":"code","id":"wx9vlNiE3nEy","outputId":"534a6e07-b38c-4ed6-8462-57c5c1d69fd4"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[71]: {&#39;chunk&#39;: [&#39;The book&#39;],\n &#39;document&#39;: [&#39;The book has many chapters&#39;],\n &#39;pos&#39;: [&#39;DT&#39;, &#39;NN&#39;, &#39;VBZ&#39;, &#39;JJ&#39;, &#39;NNS&#39;],\n &#39;token&#39;: [&#39;The&#39;, &#39;book&#39;, &#39;has&#39;, &#39;many&#39;, &#39;chapters&#39;],\n &#39;sentence&#39;: [&#39;The book has many chapters&#39;]}</div>"]}}],"execution_count":66},{"cell_type":"code","source":["result['chunk']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"DO-37mrZ3e6c","outputId":"4c0c833e-3640-4e48-ef6f-c9cdec5139b8"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[72]: [&#39;The book&#39;]</div>"]}}],"execution_count":67},{"cell_type":"code","source":["result = pipeline.annotate(\"the little yellow dog barked at the cat\") #multiple noune phrases"],"metadata":{"colab":{},"colab_type":"code","id":"btqYqgim3gWN"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":68},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"colab_type":"code","id":"zPp7aXOR3sHV","outputId":"d5b07fc3-24c8-41b5-c488-6bf68e18c470"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[74]: {&#39;chunk&#39;: [&#39;the little yellow dog&#39;, &#39;the cat&#39;],\n &#39;document&#39;: [&#39;the little yellow dog barked at the cat&#39;],\n &#39;pos&#39;: [&#39;DT&#39;, &#39;JJ&#39;, &#39;JJ&#39;, &#39;NN&#39;, &#39;JJ&#39;, &#39;IN&#39;, &#39;DT&#39;, &#39;NN&#39;],\n &#39;token&#39;: [&#39;the&#39;, &#39;little&#39;, &#39;yellow&#39;, &#39;dog&#39;, &#39;barked&#39;, &#39;at&#39;, &#39;the&#39;, &#39;cat&#39;],\n &#39;sentence&#39;: [&#39;the little yellow dog barked at the cat&#39;]}</div>"]}}],"execution_count":69},{"cell_type":"code","source":["result['chunk']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"y-Nj9H2r3htO","outputId":"8e7b8f0f-6f48-4bb5-c42a-113355eddda0"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[75]: [&#39;the little yellow dog&#39;, &#39;the cat&#39;]</div>"]}}],"execution_count":70},{"cell_type":"code","source":[""],"metadata":{"colab":{},"colab_type":"code","id":"tmwq8QCA3krn"},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":["### Extract exact dates from referential date phrases"],"metadata":{"colab_type":"text","id":"AII-7IpM_Hog"}},{"cell_type":"code","source":["pipeline = PretrainedPipeline('match_datetime', lang='en')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"f2sxECue_JLX","outputId":"e02d7c2e-b9d0-4c3e-cd6f-c6ce2dcc172e"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">match_datetime download started this may take some time.\nApprox size to download 12.9 KB\n\r[ | ]\r[ / ]\r[OK!]\n</div>"]}}],"execution_count":73},{"cell_type":"code","source":["result = pipeline.annotate(\"I saw him yesterday and he told me that he will visit us next week\")\n\nresult"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"colab_type":"code","id":"zMi_QNsh_RdX","outputId":"6faf23dc-d7f8-4974-ef83-c1a8efb2f15f"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[77]: {&#39;document&#39;: [&#39;I saw him yesterday and he told me that he will visit us next week&#39;],\n &#39;sentence&#39;: [&#39;I saw him yesterday and he told me that he will visit us next week&#39;],\n &#39;token&#39;: [&#39;I&#39;,\n  &#39;saw&#39;,\n  &#39;him&#39;,\n  &#39;yesterday&#39;,\n  &#39;and&#39;,\n  &#39;he&#39;,\n  &#39;told&#39;,\n  &#39;me&#39;,\n  &#39;that&#39;,\n  &#39;he&#39;,\n  &#39;will&#39;,\n  &#39;visit&#39;,\n  &#39;us&#39;,\n  &#39;next&#39;,\n  &#39;week&#39;],\n &#39;date&#39;: [&#39;2020/08/13&#39;, &#39;2020/08/05&#39;]}</div>"]}}],"execution_count":74},{"cell_type":"code","source":["pipeline.fullAnnotate(\"I saw him yesterday and he told me that he will visit us next week\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"colab_type":"code","id":"W76HdhULHm7q","outputId":"30a6d8db-a15b-4fa2-d27e-7a0a84b1bc4c"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[78]: [{&#39;document&#39;: [Annotation(document, 0, 65, I saw him yesterday and he told me that he will visit us next week, {})],\n  &#39;sentence&#39;: [Annotation(document, 0, 65, I saw him yesterday and he told me that he will visit us next week, {&#39;sentence&#39;: &#39;0&#39;})],\n  &#39;token&#39;: [Annotation(token, 0, 0, I, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 2, 4, saw, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 6, 8, him, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 10, 18, yesterday, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 20, 22, and, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 24, 25, he, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 30, told, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 32, 33, me, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 35, 38, that, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 40, 41, he, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 43, 46, will, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 48, 52, visit, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 54, 55, us, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 57, 60, next, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 62, 65, week, {&#39;sentence&#39;: &#39;0&#39;})],\n  &#39;date&#39;: [Annotation(date, 57, 65, 2020/08/13, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(date, 10, 18, 2020/08/05, {&#39;sentence&#39;: &#39;0&#39;})]}]</div>"]}}],"execution_count":75},{"cell_type":"code","source":["tuples = []\n\nfor x in detailed_result[0][\"token\"]:\n\n  tuples.append((int(x.metadata['sentence']), x.result, x.begin, x.end))\n\ndf = pd.DataFrame(tuples, columns=['sent_id','token','start','end'])\n\ndf"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_id</th>\n      <th>token</th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Peter</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Parker</td>\n      <td>6</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>is</td>\n      <td>13</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>a</td>\n      <td>16</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>nice</td>\n      <td>18</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>guy</td>\n      <td>23</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>and</td>\n      <td>27</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>lives</td>\n      <td>31</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>in</td>\n      <td>37</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>New</td>\n      <td>40</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>York</td>\n      <td>44</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":76},{"cell_type":"markdown","source":["### Sentiment Analysis\n#### Vivek algo"],"metadata":{"colab_type":"text","id":"VVBmv1KeJQhA"}},{"cell_type":"code","source":["pipeline = PretrainedPipeline('analyze_sentiment', lang='en')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"zOFjnAvsH6he","outputId":"eba1d2af-c10b-4095-dd06-7d856e6b5b40"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">analyze_sentiment download started this may take some time.\nApprox size to download 4.9 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[OK!]\n</div>"]}}],"execution_count":78},{"cell_type":"code","source":["result = pipeline.annotate(\"The movie I watched today was not a good one\")\n\nresult['sentiment']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"KseopzCyJe__","outputId":"65746fa5-6d4a-4ceb-e860-7c6a7b046b4a"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[81]: [&#39;negative&#39;]</div>"]}}],"execution_count":79},{"cell_type":"markdown","source":["#### DL version (trained on imdb)"],"metadata":{"colab":{},"colab_type":"code","id":"T2CM1btxJoY-"}},{"cell_type":"code","source":["sentiment_imdb = PretrainedPipeline('analyze_sentimentdl_use_imdb', lang='en')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">analyze_sentimentdl_use_imdb download started this may take some time.\nApprox size to download 935.8 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>"]}}],"execution_count":81},{"cell_type":"code","source":["sentiment_imdb_glove = PretrainedPipeline('analyze_sentimentdl_glove_imdb', lang='en')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">analyze_sentimentdl_glove_imdb download started this may take some time.\nApprox size to download 154.9 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":82},{"cell_type":"code","source":["comment = '''\nIt's a very scary film but what impressed me was how true the film sticks to the original's tricks; it isn't filled with loud in-your-face jump scares, in fact, a lot of what makes this film scary is the slick cinematography and intricate shadow play. The use of lighting and creation of atmosphere is what makes this film so tense, which is why it's perfectly suited for those who like Horror movies but without the obnoxious gore.\n'''\nresult = sentiment_imdb_glove.annotate(comment)\n\nresult['sentiment']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[84]: [&#39;positive&#39;]</div>"]}}],"execution_count":83},{"cell_type":"code","source":["sentiment_imdb_glove.fullAnnotate(comment)[0]['sentiment']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[85]: [Annotation(category, 0, 433, positive, {&#39;sentence&#39;: &#39;0&#39;, &#39;positive&#39;: &#39;0.92505074&#39;, &#39;negative&#39;: &#39;0.074949294&#39;})]</div>"]}}],"execution_count":84},{"cell_type":"markdown","source":["#### DL version (trained on twitter dataset)"],"metadata":{}},{"cell_type":"code","source":["sentiment_twitter = PretrainedPipeline('analyze_sentimentdl_use_twitter', lang='en')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">analyze_sentimentdl_use_twitter download started this may take some time.\nApprox size to download 928.3 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":86},{"cell_type":"code","source":["result = sentiment_twitter.annotate(\"The movie I watched today was not a good one\")\n\nresult['sentiment']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[87]: [&#39;negative&#39;]</div>"]}}],"execution_count":87}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4","nbconvert_exporter":"python","file_extension":".py"},"name":"1.SparkNLP_Basics","notebookId":1832622429567592,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"collapsed_sections":[],"name":"1.SparkNLP_Basics.ipynb","provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}
