{"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"colab_type":"text","id":"sXatvRX899i0"}},{"cell_type":"markdown","source":["# Text Classification with ClassifierDL"],"metadata":{"colab_type":"text","id":"Kl6fW8Fkf3vN"}},{"cell_type":"code","source":["import sparknlp\n\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\nfrom pyspark.ml import Pipeline\nimport pandas as pd\n\nprint(\"Spark NLP version\", sparknlp.version())\n\nprint(\"Apache Spark version:\", spark.version)\n\nspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"colab_type":"code","id":"KjcBNzFVgoky","outputId":"67684642-f313-449c-bf11-70eccada1bd1"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.164.162.127:43300\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.164.162.127:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":3},{"cell_type":"markdown","source":["## Load Dataset"],"metadata":{"colab_type":"text","id":"9VTK1AsahOpz"}},{"cell_type":"code","source":["! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"colab_type":"code","id":"fEYijaovgw3M","outputId":"92a9dc2b-0b45-4052-c559-510fff53d9b4"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["dbutils.fs.cp(\"file:/databricks/driver/news_category_train.csv\", \"dbfs:/\")\ndbutils.fs.cp(\"file:/databricks/driver/news_category_test.csv\", \"dbfs:/\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"colab_type":"code","id":"K0u9cOqqhS4w","outputId":"d141a727-cf25-4da5-f260-58f0e675dae8"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: True</div>"]}}],"execution_count":6},{"cell_type":"code","source":["trainDataset = spark.read \\\n      .option(\"header\", True) \\\n      .csv(\"news_category_train.csv\")\n\ntrainDataset.show(truncate=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"colab_type":"code","id":"eoTE46WThUz2","outputId":"c2754501-f84c-44ba-cfe4-1a4fb1afbe9d"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------------------------------------------------+\ncategory|                                       description|\n+--------+--------------------------------------------------+\nBusiness| Short sellers, Wall Street&#39;s dwindling band of...|\nBusiness| Private investment firm Carlyle Group, which h...|\nBusiness| Soaring crude prices plus worries about the ec...|\nBusiness| Authorities have halted oil export flows from ...|\nBusiness| Tearaway world oil prices, toppling records an...|\nBusiness| Stocks ended slightly higher on Friday but sta...|\nBusiness| Assets of the nation&#39;s retail money market mut...|\nBusiness| Retail sales bounced back a bit in July, and n...|\nBusiness|&#34; After earning a PH.D. in Sociology, Danny Baz...|\nBusiness| Short sellers, Wall Street&#39;s dwindling  band o...|\nBusiness| Soaring crude prices plus worries  about the e...|\nBusiness| OPEC can do nothing to douse scorching  oil pr...|\nBusiness| Non OPEC oil exporters should consider  increa...|\nBusiness| WASHINGTON/NEW YORK (Reuters) - The auction fo...|\nBusiness| The dollar tumbled broadly on Friday  after da...|\nBusiness|If you think you may need to help your elderly ...|\nBusiness|The purchasing power of kids is a big part of w...|\nBusiness|There is little cause for celebration in the st...|\nBusiness|The US trade deficit has exploded 19 to a recor...|\nBusiness|Oil giant Shell could be bracing itself for a t...|\n+--------+--------------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["trainDataset.count()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"P3iINSk1hc2E","outputId":"0e8d40b4-cbbf-474f-d8be-cfb88913fa21"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: 120000</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from pyspark.sql.functions import col\n\ntrainDataset.groupBy(\"category\") \\\n    .count() \\\n    .orderBy(col(\"count\").desc()) \\\n    .show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"colab_type":"code","id":"SEaUJ3xzhgLf","outputId":"ae0158b3-63bd-4d79-8f24-273a7af50dd2"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----+\ncategory|count|\n+--------+-----+\n   World|30000|\nSci/Tech|30000|\n  Sports|30000|\nBusiness|30000|\n+--------+-----+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["testDataset = spark.read \\\n      .option(\"header\", True) \\\n      .csv(\"news_category_test.csv\")\n\n\ntestDataset.groupBy(\"category\") \\\n    .count() \\\n    .orderBy(col(\"count\").desc()) \\\n    .show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"colab_type":"code","id":"1Mk82Fnkhj4N","outputId":"ee4ecdd2-4d6c-45f6-a06e-f9ca16aca807"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----+\ncategory|count|\n+--------+-----+\nBusiness| 1900|\n  Sports| 1900|\nSci/Tech| 1900|\n   World| 1900|\n+--------+-----+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# if we want to split the dataset\n'''\n(trainingData, testData) = trainDataset.randomSplit([0.7, 0.3], seed = 100)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count: \" + str(testData.count()))\n'''"],"metadata":{"colab":{},"colab_type":"code","id":"0nHTo9Fxjjwq"},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["## ClassiferDL with Word Embeddings and Text Preprocessing"],"metadata":{"colab_type":"text","id":"j3nwNAQ4ifmD"}},{"cell_type":"code","source":["document_assembler = DocumentAssembler() \\\n    .setInputCol(\"description\") \\\n    .setOutputCol(\"document\")\n    \ntokenizer = Tokenizer() \\\n  .setInputCols([\"document\"]) \\\n  .setOutputCol(\"token\")\n    \nnormalizer = Normalizer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"normalized\")\n\nstopwords_cleaner = StopWordsCleaner()\\\n      .setInputCols(\"normalized\")\\\n      .setOutputCol(\"cleanTokens\")\\\n      .setCaseSensitive(False)\n\nlemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n    .setInputCols([\"cleanTokens\"]) \\\n    .setOutputCol(\"lemma\")\n\nglove_embeddings = WordEmbeddingsModel().pretrained() \\\n .setInputCols([\"document\",'lemma'])\\\n .setOutputCol(\"embeddings\")\\\n .setCaseSensitive(False)\n\nembeddingsSentence = SentenceEmbeddings() \\\n      .setInputCols([\"document\", \"embeddings\"]) \\\n      .setOutputCol(\"sentence_embeddings\") \\\n      .setPoolingStrategy(\"AVERAGE\")\n\nclasssifierdl = ClassifierDLApproach()\\\n  .setInputCols([\"sentence_embeddings\"])\\\n  .setOutputCol(\"class\")\\\n  .setLabelColumn(\"category\")\\\n  .setMaxEpochs(3)\\\n  .setEnableOutputLogs(True)\n\nclf_pipeline = Pipeline(\n    stages=[document_assembler, \n            tokenizer,\n            normalizer,\n            stopwords_cleaner, \n            lemma, \n            glove_embeddings,\n            embeddingsSentence,\n            classsifierdl])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123},"colab_type":"code","id":"2AkxJDshietW","outputId":"1223cc66-0fa5-4903-e3a2-fc99abf05af3"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">lemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\nglove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[OK!]\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Train (8 min for 10 epochs)\nclf_pipelineModel = clf_pipeline.fit(trainDataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"colab_type":"code","id":"7QKnwlFNi2A6","outputId":"9030cb3b-9640-4624-cf1f-e5d228af4cae"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["clf_pipelineModel.stages[-1].write().overwrite().save('dbfs:/ClassifierDL_wordemb_e5')\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# get the predictions on test Set\n\npreds = clf_pipelineModel.transform(testDataset)\n"],"metadata":{"colab":{},"colab_type":"code","id":"GvJDn6C6j8BK"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["preds = clf_pipelineModel.transform(testDataset)\n\npreds.select('category','description',\"class.result\").show(10, truncate=80)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"colab_type":"code","id":"5XdH8Z3ljYpx","outputId":"807421b9-ab4d-4d6f-ae0e-013254ffe8cc"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------------------------------------------------------------------------------+----------+\ncategory|                                                                     description|    result|\n+--------+--------------------------------------------------------------------------------+----------+\nBusiness|Unions representing workers at Turner   Newall say they are &#39;disappointed&#39; af...|   [World]|\nSci/Tech| TORONTO, Canada    A second team of rocketeers competing for the  #36;10 mil...|   [World]|\nSci/Tech| A company founded by a chemistry researcher at the University of Louisville ...|   [World]|\nSci/Tech| It&#39;s barely dawn when Mike Fitzpatrick starts his shift with a blur of color...|[Business]|\nSci/Tech| Southern California&#39;s smog fighting agency went after emissions of the bovin...|   [World]|\nSci/Tech|&#34;The British Department for Education and Skills (DfES) recently launched a &#34;...|   [World]|\nSci/Tech|&#34;confessed author of the Netsky and Sasser viruses, is responsible for 70 per...|   [World]|\nSci/Tech|\\\\FOAF/LOAF  and bloom filters have a lot of interesting properties for socia...|[Business]|\nSci/Tech|&#34;Wiltshire Police warns about &#34;&#34;phishing&#34;&#34; after its fraud squad chief was ta...|   [World]|\nSci/Tech|In its first two years, the UK&#39;s dedicated card fraud unit, has recovered 36,...|   [World]|\n+--------+--------------------------------------------------------------------------------+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["\npreds_df = preds.select('category','description',\"class.result\").toPandas()\n\n# The result is an array since in Spark NLP you can have multiple sentences.\n# Let's explode the array and get the item(s) inside of result column out\npreds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n"],"metadata":{"colab":{},"colab_type":"code","id":"AZh8gMZEk0Dy"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["# due to bug in cluster mode (https://github.com/JohnSnowLabs/spark-nlp/issues/857) , as a workaround, you can just save the fitted model and then load back from dbfs and then transform on the test set. \n\nclf_pipelineModel.stages[-1].write().overwrite().save('dbfs:/ClassifierDL_wordemb_e5')\n\nclasssifierdlmodel_loaded = ClassifierDLModel.load('dbfs:/ClassifierDL_wordemb_e5')\n\nclf_pipeline_pred = Pipeline(\n    stages=[document_assembler, \n            tokenizer,\n            normalizer,\n            stopwords_cleaner, \n            lemma, \n            glove_embeddings,\n            clf_pipelineModel.stages[-2],\n            classsifierdlmodel_loaded])\n\nempty_data = spark.createDataFrame([[\"\"]]).toDF(\"description\")\n\nresult = clf_pipeline_pred.fit(empty_data).transform(testDataset)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">lemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[OK!]\nglove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["preds_df = result.select('category','description',\"class.result\").toPandas()\n\n# The result is an array since in Spark NLP you can have multiple sentences.\n# Let's explode the array and get the item(s) inside of result column out\npreds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n\n# We are going to use sklearn to evalute the results on test dataset\nfrom sklearn.metrics import classification_report\n\nprint (classification_report(preds_df['result'], preds_df['category']))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">              precision    recall  f1-score   support\n\n    Business       0.83      0.83      0.83      1889\n    Sci/Tech       0.86      0.84      0.85      1952\n      Sports       0.96      0.94      0.95      1951\n       World       0.86      0.91      0.89      1808\n\n   micro avg       0.88      0.88      0.88      7600\n   macro avg       0.88      0.88      0.88      7600\nweighted avg       0.88      0.88      0.88      7600\n\n</div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["## ClassifierDL with Universal Sentence Embeddings"],"metadata":{"colab_type":"text","id":"YbZsPrgyl8HC"}},{"cell_type":"code","source":["# actual content is inside description column\ndocument = DocumentAssembler()\\\n    .setInputCol(\"description\")\\\n    .setOutputCol(\"document\")\n    \n# we can also use sentece detector here if we want to train on and get predictions for each sentence\n\nuse = UniversalSentenceEncoder.pretrained()\\\n .setInputCols([\"document\"])\\\n .setOutputCol(\"sentence_embeddings\")\n\n# the classes/labels/categories are in category column\nclasssifierdl = ClassifierDLApproach()\\\n  .setInputCols([\"sentence_embeddings\"])\\\n  .setOutputCol(\"class\")\\\n  .setLabelColumn(\"category\")\\\n  .setMaxEpochs(5)\\\n  .setEnableOutputLogs(True)\n\nuse_clf_pipeline = Pipeline(\n    stages = [\n        document,\n        use,\n        classsifierdl\n    ])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"Ek2RfNmsl_q7","outputId":"1043979b-5f71-477c-ef3c-f5ed13ef32e5"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">tfhub_use download started this may take some time.\nApproximate size to download 923.7 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["use_pipelineModel = use_clf_pipeline.fit(trainDataset)\n# 5 epochs takes around 10 min\n"],"metadata":{"colab":{},"colab_type":"code","id":"UN_5T8wdmeDO"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["## Getting prediction from Trained model"],"metadata":{"colab_type":"text","id":"n9tXlaLYpwdG"}},{"cell_type":"code","source":["from sparknlp.base import LightPipeline\n\nlight_model = LightPipeline(use_pipelineModel)"],"metadata":{"colab":{},"colab_type":"code","id":"iNERYucrncR5"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["testDataset.select('description').take(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"colab_type":"code","id":"mVC-3fTAqGXL","outputId":"ba87203e-2291-482a-9e41-c5090bbfa1a2"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[26]: [Row(description=&#34;Unions representing workers at Turner   Newall say they are &#39;disappointed&#39; after talks with stricken parent firm Federal Mogul.&#34;),\n Row(description=&#39; TORONTO, Canada    A second team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for privately funded suborbital space flight, has officially announced the first launch date for its manned rocket.&#39;)]</div>"]}}],"execution_count":28},{"cell_type":"code","source":["text='''\nFearing the fate of Italy, the centre-right government has threatened to be merciless with those who flout tough restrictions. \nAs of Wednesday it will also include all shops being closed across Greece, with the exception of supermarkets. Banks, pharmacies, pet-stores, mobile phone stores, opticians, bakers, mini-markets, couriers and food delivery outlets are among the few that will also be allowed to remain open.\n'''\nresult = light_model.annotate(text)\n\nresult['class']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"XB6oGd02p9Fl","outputId":"e7709c50-4ffe-41ac-ad76-2a79f719d3d2"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: [&#39;Business&#39;]</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["### Saving the trained model"],"metadata":{"colab_type":"text","id":"VsxMUayzqbsO"}},{"cell_type":"code","source":["use_pipelineModel.stages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"NTiwYxf3qcE0","outputId":"a65a4570-46ba-4ed4-d4c1-68c688ea1015"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[28]: [DocumentAssembler_d2b783089b74,\n UNIVERSAL_SENTENCE_ENCODER_4de71669b7ec,\n ClassifierDLModel_edcbc2b517cb]</div>"]}}],"execution_count":31},{"cell_type":"code","source":["use_pipelineModel.stages[2].write().overwrite().save('dbfs:/ClassifierDL_USE_20200923_e5')"],"metadata":{"colab":{},"colab_type":"code","id":"7o3-H51eqfK9"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["use_classsifierdlmodel_loaded = ClassifierDLModel.load('dbfs:/ClassifierDL_USE_20200923_e5')\n"],"metadata":{"colab":{},"colab_type":"code","id":"BCbbKfDtqtVd"},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"code","source":["use_pipeline_pred = Pipeline(\n    stages=[document,\n            use_pipelineModel.stages[1],\n            use_classsifierdlmodel_loaded])\n\nempty_data = spark.createDataFrame([[\"\"]]).toDF(\"description\")\n\nuse_result = use_pipeline_pred.fit(empty_data).transform(testDataset)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["preds_df = use_result.select('category','description',\"class.result\").toPandas()\n\n# The result is an array since in Spark NLP you can have multiple sentences.\n# Let's explode the array and get the item(s) inside of result column out\npreds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n\n# We are going to use sklearn to evalute the results on test dataset\nfrom sklearn.metrics import classification_report\n\nprint (classification_report(preds_df['result'], preds_df['category']))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">              precision    recall  f1-score   support\n\n    Business       0.85      0.84      0.84      1925\n    Sci/Tech       0.88      0.85      0.86      1964\n      Sports       0.98      0.95      0.97      1959\n       World       0.86      0.93      0.89      1752\n\n   micro avg       0.89      0.89      0.89      7600\n   macro avg       0.89      0.89      0.89      7600\nweighted avg       0.89      0.89      0.89      7600\n\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":36}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4","nbconvert_exporter":"python","file_extension":".py"},"name":"5.Text_Classification_with_ClassifierDL","notebookId":3534008648166611,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"collapsed_sections":[],"name":"5.Text_Classification_with_ClassifierDL.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}
