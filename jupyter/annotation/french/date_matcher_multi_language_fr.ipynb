{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DateMatcher multi-language\n",
    "\n",
    "#### This annotator allows you to specify a source language that will be used to identify temporal keywords and extract dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "943a272c-0686-4e02-a8d9-b2849721c829",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import sparknlp\n",
    "\n",
    "# Start Spark Session with Spark NLP\n",
    "# start() functions has two parameters: gpu and spark23\n",
    "# sparknlp.start(gpu=True) will start the session with GPU support\n",
    "# sparknlp.start(spark23=True) is when you have Apache Spark 2.3.x installed\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b200e2aa-6280-4f51-9eb4-e30f660e2ba4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.43.227:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd1ed2e1c50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c0b759a0-346f-4d9f-9f01-383124c0aa05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# French examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import some articoles sentences from the news where relative dates are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a91c2626-5ef8-4e01-9563-120daf4f63f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fr_articles = [\n",
    "  (\"Le dimanche 11 juillet 2021, Chiellini a utilisé le mot Kiricocho lorsque Saka s'est approché du ballon pour le penalty.\",),\n",
    "  (\"La prochaine Coupe du monde aura lieu en novembre 2022.\",),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's  fill a DataFrame with the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cfe3f9e0-4a96-44bb-b056-0b4a5407c6dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Le dimanche 11 ju...|\n",
      "|La prochaine Coup...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articles_cols = [\"text\"]\n",
    "\n",
    "df = spark.createDataFrame(data=fr_articles, schema=articles_cols)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's create a simple pipeline to apply the DateMatcher, specifying the source language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4baf2a1-3e75-479e-9e9b-2b071624ee3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "            .setInputCol(\"text\") \\\n",
    "            .setOutputCol(\"document\")\n",
    "\n",
    "date_matcher = DateMatcher() \\\n",
    "            .setInputCols(['document']) \\\n",
    "            .setOutputCol(\"date\") \\\n",
    "            .setFormat(\"MM/dd/yyyy\") \\\n",
    "            .setSourceLanguage(\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's transform the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "10380fbb-43c1-42c3-b6d0-f02e55d75a24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|date                                             |\n",
      "+-------------------------------------------------+\n",
      "|[[date, 10, 21, 07/11/2021, [sentence -> 0], []]]|\n",
      "|[[date, 41, 53, 11/01/2022, [sentence -> 0], []]]|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembled = document_assembler.transform(df)\n",
    "date_matcher.transform(assembled).select('date').show(10, False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DateMatcherMultiLanguage_tests",
   "notebookOrigID": 2439167545177012,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
