{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAYzZXMyCYQx"
   },
   "outputs": [],
   "source": [
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxJniPtV_gqj",
    "outputId": "069698a8-614a-457e-a1b1-dbfd7dc43319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 3.1.2\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qceFcfEhr9r5"
   },
   "source": [
    "To use Merge Entities parameter we need to set allowSparkContext parameter to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luNlbsk1AJqP",
    "outputId": "133d06b8-b5a9-4075-d140-d3e9e926f9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+\n",
      "|text                                            |\n",
      "+------------------------------------------------+\n",
      "|Peter Parker is a nice lad and lives in New York|\n",
      "+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "text = ['Peter Parker is a nice lad and lives in New York']\n",
    "data_set = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
    "data_set.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSvNig972xXC"
   },
   "source": [
    "# Graph Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkW7uQ4_cqAQ"
   },
   "source": [
    "Graph Extraction will use pretrained POS, Dependency Parser and Typed Dependency Parser annotators when the pipeline does not have those defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVFs6NDBlWsN",
    "outputId": "34c81b25-024d-4ef2-cf10-1764665143a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_tagger = NerDLModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEJRu8qXg3SI"
   },
   "source": [
    "To instruct Graph Extraction to use automatically pretrained POS, Dependency and Typed Dependency Parser annotator, we need to set MergeEntities parameter to True. This parameter will merge neighbor tagging entities into one. e.g. Peter Parker will be consider a single token, before sending it to Dependency Parsers annotators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sentence, we can extract paths for the following pair of tokens-ENTITIES:\n",
    "* lad-PER, will output the path between *lad* and Peter Parker\n",
    "* lad-LOC, will output the path between *lad* and New York\n",
    "\n",
    "Any other pair of token,ENTITY will output an empty path since there is no path between them. You can visualize the dependency tree for this sentence using [sparknlp display package](https://github.com/JohnSnowLabs/spark-nlp-display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XxqysCFDg1aP"
   },
   "outputs": [],
   "source": [
    "graph_extraction = GraphExtraction() \\\n",
    "            .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "            .setOutputCol(\"graph\") \\\n",
    "            .setRelationshipTypes([\"lad-PER\", \"lad-LOC\"]) \\\n",
    "            .setMergeEntities(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEpjj9shlKMP"
   },
   "source": [
    "Under the hood it uses default pretrained annotators, but we can set any pretrained model with the parameters *setPosModel*, *setDependencyParserModel* or *setTypedDependencyParserModel*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Dms9keFa7K0"
   },
   "source": [
    "Unlike [this notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/feature/graph-extraction-tutorial/jupyter/annotation/english/graph-extraction/graph_extraction.ipynb), the pipeline below just has graph extraction + NER + tokenizer annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LRpKY22pAqlL"
   },
   "outputs": [],
   "source": [
    "           \n",
    "graph_pipeline = Pipeline().setStages([document_assembler, tokenizer,\n",
    "                                       word_embeddings, ner_tagger,\n",
    "                                       graph_extraction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJV6x-Nqw442"
   },
   "source": [
    "The result dataset has a *graph* column with the paths between lad,PER and lad-LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kh78KBe-63Dn",
    "outputId": "17dbc439-dae7-412f-9f52-ac61ece64025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|graph                                                                                                                                                               |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[node, 23, 25, lad, [relationship -> lad,PER, path1 -> lad,flat,Peter Parker], []], [node, 23, 25, lad, [relationship -> lad,LOC, path1 -> lad,flat,New York], []]]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_data_set = graph_pipeline.fit(data_set).transform(data_set)\n",
    "graph_data_set.select(\"graph\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Graph Extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
