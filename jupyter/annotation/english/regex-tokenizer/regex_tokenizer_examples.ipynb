{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Normalizer annotator notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7c65f64-07d6-4355-97a0-0a371d83116c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Set up Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install -q pyspark==2.4.7\n",
    "! pip install -q spark-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Spark NLP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "def start():\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .config(\"spark.driver.memory\", \"8G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.7.1\") \\\n",
    "        .config(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "        .config(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "    return builder.getOrCreate()\n",
    "\n",
    "spark = start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Tokenizer annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b4efb61f-6011-4ba1-a0ad-6c229f69e3d9",
     "showTitle": true,
     "title": "DocumentNormalizer overview and parameters"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import StringType\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "import sparknlp\n",
    "\n",
    "content = \"1. T1-T2 DATE**[12/24/13] $1.99 () (10/12), ph+ 90%\"\n",
    "pattern = \"\\\\s+|(?=[-.:;*+,$&%\\\\[\\\\]])|(?<=[-.:;*+,$&%\\\\[\\\\]])\"\n",
    "\n",
    "df = spark.createDataFrame([content], StringType()).withColumnRenamed(\"value\", \"text\")\n",
    "\n",
    "df.show()\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = RegexTokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"regexToken\") \\\n",
    "      .setPattern(pattern) \\\n",
    "      .setPositionalMask(False)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.show(10, False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "DocumentNormalizer_notebook_doc",
   "notebookOrigID": 3142402907558969,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:spknlp270] *",
   "language": "python",
   "name": "conda-env-spknlp270-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
