{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Export BERT model to Spark NLP - BertEmbeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A0TRN_85WNj",
        "colab_type": "text"
      },
      "source": [
        "# How to import BERT checkpoints into Spark NLP\n",
        "## We use BERTimbau - Portuguese BERT as an example\n",
        "source: https://github.com/neuralmind-ai/portuguese-bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdQrXRANgcio",
        "colab_type": "text"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/portuguese/Export_BERT_model_to_Spark_NLP_BertEmbeddings.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msCesFECu5ug",
        "colab_type": "text"
      },
      "source": [
        "Install TensorFlow 1.15.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxnRNkkDuvhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "72d01c15-e6b1-4ec6-9ca2-2e446ac1e85f"
      },
      "source": [
        "! pip install -q tensorflow==1.15.0 tensorflow-hub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 412.3MB 31kB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 48.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 51.3MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQS1xIBX7Nv8",
        "colab_type": "text"
      },
      "source": [
        "We need `modeling` from original BERT repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhZJ0ln5wkh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f39625bb-1aa3-4a81-8d0d-03f3225cf417"
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 317.85 KiB | 4.18 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X3RcahYv3QU",
        "colab_type": "text"
      },
      "source": [
        "Let's start Apache Spark with Spark NLP, we'll use this later to save BertEmbeddings model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmL9n8xtvDhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "93dcfe8b-1827-4021-e222-c657457b0170"
      },
      "source": [
        "import sys\n",
        "import tensorflow.compat.v1 as tf\n",
        "from bert import modeling\n",
        "import shutil\n",
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "tf.get_logger().setLevel('WARN')\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "1.15.0\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urIOmg-5whtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(config_path, meta_path, ckpt_path, export_dir):\n",
        "\n",
        "    with tf.Graph().as_default():\n",
        "        tf.random.set_random_seed(44)\n",
        "        # these names are important, we look for these in Spark NLP when we feed the BERT model\n",
        "        bert_inputs = dict(\n",
        "            input_ids=tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"input_ids\"),\n",
        "            input_mask=tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"input_mask\"),\n",
        "            segment_ids=tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"segment_ids\")\n",
        "        )\n",
        "\n",
        "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                              log_device_placement=False)) as sess:\n",
        "\n",
        "            with tf.device('/gpu:0'):\n",
        "\n",
        "                bert_config = modeling.BertConfig.from_json_file(config_path)\n",
        "\n",
        "                model = modeling.BertModel(\n",
        "                    config=bert_config,\n",
        "                    is_training=False,\n",
        "                    input_ids=bert_inputs['input_ids'],\n",
        "                    input_mask=bert_inputs['input_mask'],\n",
        "                    token_type_ids=bert_inputs['segment_ids'],\n",
        "                    use_one_hot_embeddings=False\n",
        "                )\n",
        "\n",
        "                # this name is important, we look for this when we want to fetch the result\n",
        "                # as you already guessed, you can do whatever you want within the TensorFlow with this output\n",
        "                # as long as the result is DT_FLOAT with the shape of (-1, -1, 768) you can use the same name \n",
        "                # and access the results in Spark NLP               \n",
        "                sequence_output = tf.identity(model.get_sequence_output(), name=\"sequence_output\")\n",
        "                bert_outputs = dict(\n",
        "                    sequence_output=sequence_output\n",
        "                )\n",
        "\n",
        "                tf.train.Saver().restore(sess, ckpt_path)\n",
        "\n",
        "                init_op = tf.group([tf.global_variables_initializer(),\n",
        "                                    tf.initializers.tables_initializer(name='init_all_tables')])\n",
        "\n",
        "                sess.run(init_op)\n",
        "\n",
        "                shutil.rmtree(export_dir, ignore_errors=True)\n",
        "\n",
        "                tf.saved_model.simple_save(\n",
        "                    sess,\n",
        "                    export_dir,\n",
        "                    inputs=bert_inputs,\n",
        "                    outputs=bert_outputs,\n",
        "                    legacy_init_op=init_op\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNxgvfyuxhB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "d3c691d1-563e-4295-d456-923d6c09ac89"
      },
      "source": [
        "# Let's download some BERT Checkpoints\n",
        "!wget https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_tensorflow_checkpoint.zip\n",
        "!unzip bert-base-portuguese-cased_tensorflow_checkpoint.zip -d bert-base-portuguese-cased_tensorflow_checkpoint\n",
        "\n",
        "# For some reason portuguese vocab.txt is not included in the model, \n",
        "# it has to be downloaded separately\n",
        "# most BERT models come with the vocab.txt included\n",
        "!wget -P bert-base-portuguese-cased_tensorflow_checkpoint \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/vocab.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-10 11:54:28--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_tensorflow_checkpoint.zip\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.88.48\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.88.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1205655266 (1.1G) [application/zip]\n",
            "Saving to: ‘bert-base-portuguese-cased_tensorflow_checkpoint.zip’\n",
            "\n",
            "bert-base-portugues 100%[===================>]   1.12G  97.4MB/s    in 13s     \n",
            "\n",
            "2020-09-10 11:54:42 (85.6 MB/s) - ‘bert-base-portuguese-cased_tensorflow_checkpoint.zip’ saved [1205655266/1205655266]\n",
            "\n",
            "Archive:  bert-base-portuguese-cased_tensorflow_checkpoint.zip\n",
            "  inflating: bert-base-portuguese-cased_tensorflow_checkpoint/bert_config.json  \n",
            "  inflating: bert-base-portuguese-cased_tensorflow_checkpoint/model.ckpt.data-00000-of-00001  \n",
            "  inflating: bert-base-portuguese-cased_tensorflow_checkpoint/model.ckpt.index  \n",
            "  inflating: bert-base-portuguese-cased_tensorflow_checkpoint/model.ckpt.meta  \n",
            "--2020-09-10 11:55:03--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/vocab.txt\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.80.144\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.80.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209528 (205K) [text/plain]\n",
            "Saving to: ‘bert-base-portuguese-cased_tensorflow_checkpoint/vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 204.62K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-09-10 11:55:03 (2.42 MB/s) - ‘bert-base-portuguese-cased_tensorflow_checkpoint/vocab.txt’ saved [209528/209528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CABWghQtxrKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def export_bert(pretrain_path, save_path):\n",
        "\n",
        "    config_path = pretrain_path + '/bert_config.json'\n",
        "    meta_path = pretrain_path + '/model.ckpt.meta'\n",
        "    ckpt_path = pretrain_path + '/model.ckpt'\n",
        "    vocab = pretrain_path + '/vocab.txt'\n",
        "\n",
        "    save_model(config_path, meta_path, ckpt_path, save_path)\n",
        "    os.makedirs(os.path.dirname(save_path+\"/assets/\"), exist_ok=True)\n",
        "    # Spark NLP needs vocab.txt in assets with the same name\n",
        "    copyfile(vocab, save_path+\"/assets/vocab.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqYWPEfS0PJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "aac0613e-d8dd-4829-be00-f646d8cee081"
      },
      "source": [
        "export_bert('/content/bert-base-portuguese-cased_tensorflow_checkpoint', './bert_saved_models/bert-base-portuguese-cased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-b48c5f128af9>:51: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUS0JCK51pqz",
        "colab_type": "text"
      },
      "source": [
        "This is how the SavedModel looks like in terms of inputs and outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au80TC0y06m4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "dc5cb3f0-2605-48ae-83db-19b98f2976a4"
      },
      "source": [
        "!saved_model_cli show --all --dir /content/bert_saved_models/bert-base-portuguese-cased/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, -1)\n",
            "        name: input_ids:0\n",
            "    inputs['input_mask'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, -1)\n",
            "        name: input_mask:0\n",
            "    inputs['segment_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, -1)\n",
            "        name: segment_ids:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['sequence_output'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, -1, 768)\n",
            "        name: sequence_output:0\n",
            "  Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IkhiSzG1wsl",
        "colab_type": "text"
      },
      "source": [
        "Let's loadd our new BERT SavedModel in TF as `BertEmbeddings` model in Spark NLP:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOqC2G1x2a5u",
        "colab_type": "text"
      },
      "source": [
        "Let's setup Apache Spark and Java first (`only for Google Colab`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZYnihY02aMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9ac15fd0-e517-43a4-d027-f9be5326cf52"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq  > /dev/null\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install -q pyspark==2.4.6\n",
        "! pip install -q spark-nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0spYbzH2iFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sparknlp\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "spark=sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQR5VaZY1l1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need to pass the path to the SavedModel and\n",
        "# the active SparkSession\n",
        "bert = BertEmbeddings.loadSavedModel('/content/bert_saved_models/bert-base-portuguese-cased/', spark)\\\n",
        " .setInputCols([\"sentence\", \"token\"])\\\n",
        " .setOutputCol(\"bert\")\\\n",
        " .setCaseSensitive(True)\\\n",
        " .setDimension(768)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZLTzmVP2qX0",
        "colab_type": "text"
      },
      "source": [
        "The `bert` variable is actually the final BertEmbeddings model. You can either use it directly in your Pipeline, or you can save it and load it later without the need to keep the BERT SavedModel like pretrained models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V976lzWa2nws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert.write().save('./BertEmbeddings_bert-base-portuguese-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvZhr6te3umv",
        "colab_type": "text"
      },
      "source": [
        "Let's use our Portuguese `BertEmbeddings` model in a pipeline for a test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6hNkm_83KSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "# you can load an offline model by using .load(PATH)\n",
        "bert = BertEmbeddings.load('/content/BertEmbeddings_bert-base-portuguese-cased') \\\n",
        " .setInputCols([\"sentence\", \"token\"])\\\n",
        " .setOutputCol(\"bert\")\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        bert        \n",
        "    ]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYcFiA-R4Oa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_data = spark.createDataFrame([[\"A alemanha é um lugar legal\"]]).toDF(\"text\")\n",
        "\n",
        "prediction = pipeline.fit(prediction_data).transform(prediction_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4MCKctx4plO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a45b0858-e82e-43a4-c952-1b16a4963498"
      },
      "source": [
        "# Tokens from Tokenizer\n",
        "prediction.select(\"bert.result\").show(1, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------+\n",
            "|result                            |\n",
            "+----------------------------------+\n",
            "|[A, alemanha, é, um, lugar, legal]|\n",
            "+----------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCPRh_X34t47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "23bb2595-c493-4393-907d-64490b41cf0f"
      },
      "source": [
        "# Embeddings from Portuguese BERT SavedModel\n",
        "prediction.select(\"bert.embeddings\").show(1, truncate=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------------------------------------------------+\n",
            "|                                                                                          embeddings|\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "|[[0.7554269, -1.4238819, 0.2617143, -0.39890784, 0.1543039, 0.07270624, 0.2696601, -0.39731884, -...|\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAnj3s2E5CsW",
        "colab_type": "text"
      },
      "source": [
        "You can remove everything exccept `BertEmbeddings_bert-base-portuguese-cased` which is all you need. You can zip it and download it for later! :) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR55fjsH4249",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f954260f-bea2-40b3-d13c-56dfb5813b58"
      },
      "source": [
        "!zip -r /content/BertEmbeddings_bert-base-portuguese-cased.zip /content/BertEmbeddings_bert-base-portuguese-cased/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/ (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/bert_tensorflow (deflated 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/fields/ (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/fields/vocabulary/ (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/fields/vocabulary/.part-00001.crc (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/fields/vocabulary/.part-00000.crc (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/fields/vocabulary/part-00000 (deflated 78%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/fields/vocabulary/part-00001 (deflated 78%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/fields/vocabulary/_SUCCESS (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/fields/vocabulary/._SUCCESS.crc (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/metadata/ (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/metadata/part-00000 (deflated 35%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/metadata/_SUCCESS (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: content/BertEmbeddings_bert-base-portuguese-cased/.bert_tensorflow.crc (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIQbkUwd6F5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}