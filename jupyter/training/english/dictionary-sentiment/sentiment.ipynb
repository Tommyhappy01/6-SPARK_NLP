{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4BBN50oyiwG"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dictionary-sentiment/sentiment.ipynb)\n",
    "\n",
    "## 0. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64719,
     "status": "ok",
     "timestamp": 1589641853953,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "nTH23Yu1yqfD",
    "outputId": "7a6fa535-d869-48be-e49f-e4e36d7e9059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 63kB/s \n",
      "\u001b[K     |████████████████████████████████| 204kB 48.0MB/s \n",
      "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 122kB 2.7MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ow6rjyOyiwN"
   },
   "source": [
    "## Rule-based Sentiment Analysis\n",
    "\n",
    "In the following example, we walk-through a simple use case for our straight forward SentimentDetector annotator.\n",
    "\n",
    "This annotator will work on top of a list of labeled sentences which can have any of the following features\n",
    "    \n",
    "    positive\n",
    "    negative\n",
    "    revert\n",
    "    increment\n",
    "    decrement\n",
    "\n",
    "Each of these sentences will be used for giving a score to text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_1aCdWNyiwQ"
   },
   "source": [
    "#### 1. Call necessary imports and set the resource path to read local data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIH8pFdPyiwS"
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import array_contains\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58CQiS99yiwh"
   },
   "source": [
    "#### 2. Load SparkSession if not already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 132364,
     "status": "ok",
     "timestamp": 1589641921624,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "Ub7u0Z2yyiwj",
    "outputId": "bc752875-2714-41d1-8eef-483c7481ae79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.5.0\n",
      "Apache Spark version:  2.4.4\n"
     ]
    }
   ],
   "source": [
    "import sparknlp \n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 148313,
     "status": "ok",
     "timestamp": 1589641937579,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "XYXJ8Lrhyiwz",
    "outputId": "e3ee6935-80e6-43a6-8787-db65564c832e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/tmp/sentiment.parquet.zip': No such file or directory\n",
      "--2020-05-16 15:12:05--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.37.174\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.37.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76127532 (73M) [application/zip]\n",
      "Saving to: ‘/tmp/sentiment.parquet.zip’\n",
      "\n",
      "sentiment.parquet.z 100%[===================>]  72.60M  16.5MB/s    in 5.6s    \n",
      "\n",
      "2020-05-16 15:12:11 (12.9 MB/s) - ‘/tmp/sentiment.parquet.zip’ saved [76127532/76127532]\n",
      "\n",
      "--2020-05-16 15:12:13--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/lemma-corpus-small/lemmas_small.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.24.174\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.24.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 189437 (185K) [text/plain]\n",
      "Saving to: ‘/tmp/lemmas_small.txt’\n",
      "\n",
      "lemmas_small.txt    100%[===================>] 185.00K   341KB/s    in 0.5s    \n",
      "\n",
      "2020-05-16 15:12:14 (341 KB/s) - ‘/tmp/lemmas_small.txt’ saved [189437/189437]\n",
      "\n",
      "--2020-05-16 15:12:15--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/default-sentiment-dict.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.186.197\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.186.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 289 [text/plain]\n",
      "Saving to: ‘/tmp/default-sentiment-dict.txt’\n",
      "\n",
      "default-sentiment-d 100%[===================>]     289  --.-KB/s    in 0s      \n",
      "\n",
      "2020-05-16 15:12:16 (12.8 MB/s) - ‘/tmp/default-sentiment-dict.txt’ saved [289/289]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! rm /tmp/sentiment.parquet.zip\n",
    "! rm -rf /tmp/sentiment.parquet\n",
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip -P /tmp\n",
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/lemma-corpus-small/lemmas_small.txt -P /tmp\n",
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/default-sentiment-dict.txt -P /tmp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 152121,
     "status": "ok",
     "timestamp": 1589641941394,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "zu_lzjvXyiw6",
    "outputId": "aa12f375-7d0e-48e6-95f8-7c3299987d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/sentiment.parquet.zip\n",
      "   creating: /tmp/sentiment.parquet/\n",
      "  inflating: /tmp/sentiment.parquet/.part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      " extracting: /tmp/sentiment.parquet/_SUCCESS  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n"
     ]
    }
   ],
   "source": [
    "! unzip /tmp/sentiment.parquet.zip -d /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160363,
     "status": "ok",
     "timestamp": 1589641949644,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "8ycCJ0Vyyiw_",
    "outputId": "8a2515c3-66ab-4ed5-9f46-7e0ad1944c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+\n",
      "|itemid|sentiment|                text|\n",
      "+------+---------+--------------------+\n",
      "|     1|        0|                 ...|\n",
      "|     2|        0|                 ...|\n",
      "|     3|        1|              omg...|\n",
      "|     4|        0|          .. Omga...|\n",
      "|     5|        0|         i think ...|\n",
      "|     6|        0|         or i jus...|\n",
      "|     7|        1|       Juuuuuuuuu...|\n",
      "|     8|        0|       Sunny Agai...|\n",
      "|     9|        1|      handed in m...|\n",
      "|    10|        1|      hmmmm.... i...|\n",
      "|    11|        0|      I must thin...|\n",
      "|    12|        1|      thanks to a...|\n",
      "|    13|        0|      this weeken...|\n",
      "|    14|        0|     jb isnt show...|\n",
      "|    15|        0|     ok thats it ...|\n",
      "|    16|        0|    &lt;-------- ...|\n",
      "|    17|        0|    awhhe man.......|\n",
      "|    18|        1|    Feeling stran...|\n",
      "|    19|        0|    HUGE roll of ...|\n",
      "|    20|        0|    I just cut my...|\n",
      "+------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark. \\\n",
    "        read. \\\n",
    "        parquet(\"/tmp/sentiment.parquet\"). \\\n",
    "        limit(10000).cache()\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPH7HLK8yixE"
   },
   "source": [
    "#### 3. Create appropriate annotators. We are using Sentence Detection, Tokenizing the sentences, and find the lemmas of those tokens. The Finisher will only output the Sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPDSRAXtyixG"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "lemmatizer = Lemmatizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"lemma\") \\\n",
    "    .setDictionary(\"/tmp/lemmas_small.txt\", key_delimiter=\"->\", value_delimiter=\"\\t\")\n",
    "        \n",
    "sentiment_detector = SentimentDetector() \\\n",
    "    .setInputCols([\"lemma\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"sentiment_score\") \\\n",
    "    .setDictionary(\"/tmp/default-sentiment-dict.txt\", \",\")\n",
    "    \n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"sentiment_score\"]) \\\n",
    "    .setOutputCols([\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tYe_QijyixO"
   },
   "source": [
    "#### 4. Train the pipeline, which is only being trained from external resources, not from the dataset we pass on. The prediction runs on the target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o53EAomsyixQ"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, lemmatizer, sentiment_detector, finisher])\n",
    "model = pipeline.fit(data)\n",
    "result = model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgvlQ7TiyixV"
   },
   "source": [
    "#### 5. filter the finisher output, to find the positive sentiment lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 163295,
     "status": "ok",
     "timestamp": 1589641952604,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "FD8jYLEsyixW",
    "outputId": "47d7fcc6-08e0-40ed-9de2-38947ba01c13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|itemid|sentiment |text                                                                                                                                |\n",
      "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1     |[positive]|                     is so sad for my APL friend.............                                                                       |\n",
      "|2     |[positive]|                   I missed the New Moon trailer...                                                                                 |\n",
      "|3     |[positive]|              omg its already 7:30 :O                                                                                               |\n",
      "|4     |[positive]|          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...|\n",
      "|5     |[positive]|         i think mi bf is cheating on me!!!       T_T                                                                               |\n",
      "|6     |[positive]|         or i just worry too much?                                                                                                  |\n",
      "|7     |[positive]|       Juuuuuuuuuuuuuuuuussssst Chillin!!                                                                                           |\n",
      "|8     |[positive]|       Sunny Again        Work Tomorrow  :-|       TV Tonight                                                                       |\n",
      "|9     |[positive]|      handed in my uniform today . i miss you already                                                                               |\n",
      "|10    |[positive]|      hmmmm.... i wonder how she my number @-)                                                                                      |\n",
      "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.where(array_contains(result.sentiment, \"positive\")).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8pjkB7Zyixd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
